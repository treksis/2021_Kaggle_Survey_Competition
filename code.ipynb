{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.options.display.max_colwidth\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "data_2021 = pd.read_csv('../input/kaggle-survey-2021/kaggle_survey_2021_responses.csv', low_memory = False, encoding='UTF-8')\n",
    "questions_2021 = data_2021.iloc[0, :].T\n",
    "data_2021 = data_2021.iloc[1:, :]\n",
    "data_2020 = pd.read_csv('../input/kaggle-survey-2020/kaggle_survey_2020_responses.csv', low_memory = False, encoding='UTF-8')\n",
    "questions_2020 = data_2020.iloc[0, :].T\n",
    "data_2020 = data_2020.iloc[1:, :]\n",
    "data_2019 = pd.read_csv('../input/kaggle-survey-2019/multiple_choice_responses.csv', low_memory = False, encoding='UTF-8')\n",
    "questions_2019 = data_2019.iloc[0, :].T\n",
    "data_2019 = data_2019.iloc[1:, :]\n",
    "data_2018 = pd.read_csv('../input/kaggle-survey-2018/multipleChoiceResponses.csv', low_memory = False, encoding='UTF-8')\n",
    "questions_2018 = data_2018.iloc[0, :].T\n",
    "data_2018 = data_2018.iloc[1:, :]\n",
    "data_2017 = pd.read_csv('../input/kaggle-survey-2017/multipleChoiceResponses.csv', low_memory = False, encoding='ISO-8859-1')\n",
    "questions_2017 = data_2017.iloc[0, :].T\n",
    "data_2017 = data_2017.iloc[1:, :]\n",
    "\n",
    "!pip install openpyxl\n",
    "\n",
    "nvda_earnings = pd.read_excel('../input/stonks-data/nvda_earnings.xlsx')\n",
    "cloud_earnings = pd.read_excel('../input/stonks-data/cloud.xlsx')\n",
    "# 2021 Yes. 2020 Yes. 2019 Yes. About TPUs\n",
    "\n",
    "def get_professionals(data, column):\n",
    "    data = data.loc[data[column] != 'Student']\n",
    "    data = data.loc[data[column] != 'Currently not employed']\n",
    "    data = data.loc[data[column] != 'Not employed']\n",
    "    data = data.loc[data[column].notna()]\n",
    "    return data\n",
    "\n",
    "pros_2021 = get_professionals(data_2021, 'Q5')\n",
    "pros_2020 = get_professionals(data_2020, 'Q5')\n",
    "\n",
    "pros_2019 = data_2019[data_2019['Q5'].notna()]\n",
    "pros_2019 = pros_2019[pros_2019['Q5'] != 'Student']\n",
    "pros_2019 = pros_2019[pros_2019['Q5'] != 'Not employed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_source(x):\n",
    "    if x == 'MySQL':\n",
    "        return 1\n",
    "    elif x == 'PostgreSQL':\n",
    "        return 1\n",
    "    elif x == 'MongoDB':\n",
    "        return 1\n",
    "    elif x == 'SQLite':\n",
    "        return 1\n",
    "    elif x == 'PostgresSQL':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def aws(x):\n",
    "    if 'Amazon' in x:\n",
    "        return 1\n",
    "    elif 'AWS' in x:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def gcp(x):\n",
    "    if 'Google' in x:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def azure(x):\n",
    "    if 'Microsoft' in x:\n",
    "        return 1\n",
    "    elif 'Azure' in x:\n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "    \n",
    "def annotate_axes(fig):\n",
    "    for i, ax in enumerate(fig.axes):\n",
    "        ax.text(0.5, 0.5, \"ax%d\" % (i+1), va=\"center\", ha=\"center\")\n",
    "        ax.tick_params(labelbottom=False, labelleft=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2021 Q.27 Cloud Computing Platform ---\n",
    "\n",
    "cloud_2021 = ['Q27_A_Part_1','Q27_A_Part_2','Q27_A_Part_3','Q27_A_Part_4','Q27_A_Part_5','Q27_A_Part_6','Q27_A_Part_7','Q27_A_Part_8', 'Q27_A_Part_9','Q27_A_Part_10','Q27_A_Part_11','Q27_A_OTHER']\n",
    "df_2021 = pros_2021[cloud_2021]\n",
    "\n",
    "count_2021 = pd.Series(df_2021[cloud_2021].squeeze().values.ravel()).value_counts()\n",
    "\n",
    "df_count_2021 = pd.DataFrame(count_2021)\n",
    "df_count_2021 = df_count_2021.reset_index()\n",
    "df_count_2021.columns = ['Cloud', 'Counts']\n",
    "\n",
    "# --- 2020 Q.26 Cloud Computing Platform ---\n",
    "\n",
    "cloud_2020 = ['Q26_A_Part_1','Q26_A_Part_2','Q26_A_Part_3','Q26_A_Part_4','Q26_A_Part_5','Q26_A_Part_6', 'Q26_A_Part_7','Q26_A_Part_8','Q26_A_Part_9','Q26_A_Part_10','Q26_A_Part_11','Q26_A_OTHER']\n",
    "df_2020 = pros_2020[cloud_2020]\n",
    "\n",
    "count_2020 = pd.Series(df_2020[cloud_2020].squeeze().values.ravel()).value_counts()\n",
    "\n",
    "df_count_2020 = pd.DataFrame(count_2020)\n",
    "df_count_2020 = df_count_2020.reset_index()\n",
    "df_count_2020.columns = ['Cloud', 'Counts']\n",
    "\n",
    "# --- 2019 Q.29 Cloud Computing Platform ---\n",
    "\n",
    "cloud_2019 = ['Q29_Part_1','Q29_Part_2','Q29_Part_3','Q29_Part_4','Q29_Part_5','Q29_Part_6','Q29_Part_7', 'Q29_Part_8','Q29_Part_9','Q29_Part_10','Q29_Part_11','Q29_Part_12']\n",
    "df_2019 = pros_2019[cloud_2019]\n",
    "\n",
    "count_2019 = pd.Series(df_2019[cloud_2019].squeeze().values.ravel()).value_counts()\n",
    "\n",
    "df_count_2019 = pd.DataFrame(count_2019)\n",
    "df_count_2019 = df_count_2019.reset_index()\n",
    "df_count_2019.columns = ['Cloud', 'Counts']\n",
    "df_count_2019 = df_count_2019.append({'Cloud':'IBM Cloud / Red Hat', 'Counts': 451}, ignore_index=True).append({'Cloud':'Tencent Cloud', 'Counts': None}, ignore_index=True)\n",
    "df_count_2019 = df_count_2019.drop([4,11]).reset_index(drop = True)\n",
    "\n",
    "# --- Merge All Three ---\n",
    "\n",
    "cloud_df = df_count_2021.merge(df_count_2020, on = 'Cloud').merge(df_count_2019, how = 'left')\n",
    "cloud_df['Counts'][4] = 451\n",
    "cloud_df = cloud_df.rename(columns = {'Cloud': 'Cloud', 'Counts_x':'2021', 'Counts_y': '2020', 'Counts': '2019'})\n",
    "cloud_df_bar = cloud_df.set_index('Cloud').T[::-1]\n",
    "\n",
    "cloud_df_bar.columns = cloud_df_bar.columns.str.strip()\n",
    "cloud_df_bar = cloud_df_bar.rename(columns = {'Amazon Web Services (AWS)': 'AWS',\n",
    "                                             'Google Cloud Platform (GCP)': 'GCP',\n",
    "                                             'Microsoft Azure': 'Azure',\n",
    "                                             'IBM Cloud / Red Hat': 'IBM',\n",
    "                                             'Oracle Cloud': 'Oracle',\n",
    "                                              'VMware Cloud': 'VMware',\n",
    "                                              'SAP Cloud': 'SAP',\n",
    "                                              'Salesforce Cloud': 'Salesforce',\n",
    "                                              'Alibaba Cloud': 'Alibaba',\n",
    "                                              'Tencent Cloud': 'Tencent'\n",
    "                                             })\n",
    "\n",
    "# --- Plot ---\n",
    "\n",
    "plt.style.use('classic')\n",
    "plt.rcParams['font.size'] = 20\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "\n",
    "cloud_df_bar.plot(kind = 'bar', \n",
    "                  ax = ax,\n",
    "                  color = ('#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f','#7f7f7f'),\n",
    "                  width = 1)\n",
    "\n",
    "ax.set_title(\"Cloud computing platform usage\", fontsize ='large', pad=20)\n",
    "ax.set_xlabel('Year', fontsize='medium', labelpad=20)\n",
    "ax.set_ylabel('Number of respondents', fontsize='medium', labelpad=20)\n",
    "ax.legend(bbox_to_anchor = (1.4, 0.8), fontsize=20)\n",
    "\n",
    "plt.savefig('1.1 Cloud Computing Platform Usage.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cloud Computing Platform Market Share ---\n",
    "\n",
    "for_perc = cloud_df_bar\n",
    "for_perc = for_perc.divide(for_perc.sum(axis=1), axis = 0)\n",
    "\n",
    "# --- Plot ---\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "for_perc.plot(kind='area',\n",
    "              stacked=True,\n",
    "              ax = ax,\n",
    "              color = ('#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f','#7f7f7f')\n",
    "             )\n",
    "\n",
    "ax.annotate('Share of None is decreasing',\n",
    "             xy=(1.6, 0.53),\n",
    "             xytext=(0.3, 0.58),\n",
    "             arrowprops = dict(facecolor='black', shrink=0.05),\n",
    "             fontsize=20,\n",
    "            )\n",
    "\n",
    "ax.set_title(\"Cloud computing platform usage by share\", fontsize ='large', pad=20)\n",
    "ax.set_xlabel('Year', fontsize='medium', labelpad=20)\n",
    "ax.set_ylabel('Percentage', fontsize='medium', labelpad=20)\n",
    "ax.legend(bbox_to_anchor = (1.4, 0.8), fontsize=20)\n",
    "\n",
    "plt.savefig('1.2 Cloud Computing Platform Usage by share.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2021 Q27. The best developer's experience with ---\n",
    "\n",
    "cloud_2_year_list = ['Q27_A_Part_1',\n",
    "          'Q27_A_Part_2',\n",
    "          'Q27_A_Part_3',\n",
    "          'Q27_A_Part_4',\n",
    "          'Q27_A_Part_5',\n",
    "          'Q27_A_Part_6',\n",
    "          'Q27_A_Part_7',\n",
    "          'Q27_A_Part_8',\n",
    "          'Q27_A_Part_9',\n",
    "          'Q27_A_Part_10',\n",
    "          'Q27_A_Part_11',\n",
    "          'Q27_A_OTHER']\n",
    "\n",
    "cloud_2_year_later = pros_2021[cloud_2_year_list]\n",
    "\n",
    "count_cloud_2_year_later = pd.Series(cloud_2_year_later[cloud_2_year_list].squeeze().values.ravel()).value_counts()\n",
    "df_count_cloud_2_year_later = pd.DataFrame(count_cloud_2_year_later).reset_index()\n",
    "df_count_cloud_2_year_later.columns = ['Cloud', '2021']\n",
    "df_count_cloud_2_year_later = df_count_cloud_2_year_later.set_index('Cloud').T\n",
    "\n",
    "\n",
    "cloud_best_exp = pd.Series(pros_2021['Q28'].squeeze().values.ravel()).value_counts()\n",
    "df_cloud_best_exp = pd.DataFrame(cloud_best_exp).reset_index()\n",
    "df_cloud_best_exp.columns = ['Cloud', '2021']\n",
    "df_cloud_best_exp = df_cloud_best_exp.set_index('Cloud').T\n",
    "df_cloud_best_exp.columns = df_cloud_best_exp.columns.str.strip()\n",
    "df_cloud_best_exp = df_cloud_best_exp.rename(columns = {'Amazon Web Services (AWS)': 'AWS',\n",
    "                                             'Google Cloud Platform (GCP)': 'GCP',\n",
    "                                            'They all had a similarly enjoyable developer experience':'All similar',\n",
    "                                             'Microsoft Azure': 'Azure',\n",
    "                                                        'None were satisfactory':'All bad',\n",
    "                                             'IBM Cloud / Red Hat': 'IBM',\n",
    "                                             'Oracle Cloud': 'Oracle',\n",
    "                                              'VMware Cloud': 'VMware',\n",
    "                                              'SAP Cloud': 'SAP',\n",
    "                                              'Salesforce Cloud': 'Salesforce',\n",
    "                                              'Alibaba Cloud': 'Alibaba',\n",
    "                                              'Tencent Cloud': 'Tencent'\n",
    "                                             })\n",
    "\n",
    "# --- Plot ---\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "\n",
    "df_cloud_best_exp.plot(kind = 'bar',\n",
    "                       ax = ax,\n",
    "                       color = ('#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f','#7f7f7f', '#7f7f7f'))\n",
    "                        # AWS = Blue, GCP = Red, Azure = Orange\n",
    "\n",
    "ax.set_title(\"Cloud platform with the best developer experience\", fontsize ='large', pad=20)\n",
    "ax.set_xlabel('Year', fontsize='medium', labelpad=20)\n",
    "ax.set_ylabel('Percentage', fontsize='medium', labelpad=20)\n",
    "ax.legend(bbox_to_anchor = (1.4, 0.8), fontsize=20)\n",
    "\n",
    "plt.savefig('1.3 Cloud Platform with the best developer experience.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2021 Q27_B Future Preference ---\n",
    "\n",
    "cloud_2_year_list = ['Q27_B_Part_1',\n",
    "          'Q27_B_Part_2',\n",
    "          'Q27_B_Part_3',\n",
    "          'Q27_B_Part_4',\n",
    "          'Q27_B_Part_5',\n",
    "          'Q27_B_Part_6',\n",
    "          'Q27_B_Part_7',\n",
    "          'Q27_B_Part_8',\n",
    "          'Q27_B_Part_9',\n",
    "          'Q27_B_Part_10',\n",
    "          'Q27_B_Part_11',\n",
    "          'Q27_B_OTHER']\n",
    "\n",
    "cloud_2_year_later = pros_2021[cloud_2_year_list]\n",
    "\n",
    "count_cloud_2_year_later = pd.Series(cloud_2_year_later[cloud_2_year_list].squeeze().values.ravel()).value_counts()\n",
    "df_count_cloud_2_year_later = pd.DataFrame(count_cloud_2_year_later).reset_index()\n",
    "df_count_cloud_2_year_later.columns = ['Cloud', '2021']\n",
    "df_count_cloud_2_year_later = df_count_cloud_2_year_later.set_index('Cloud').T\n",
    "\n",
    "df_count_cloud_2_year_later.columns = df_count_cloud_2_year_later.columns.str.strip()\n",
    "df_count_cloud_2_year_later = df_count_cloud_2_year_later.rename(columns = {'Amazon Web Services (AWS)': 'AWS',\n",
    "                                             'Google Cloud Platform (GCP)': 'GCP',\n",
    "                                             'Microsoft Azure': 'Azure',\n",
    "                                             'IBM Cloud / Red Hat': 'IBM',\n",
    "                                             'Oracle Cloud': 'Oracle',\n",
    "                                              'VMware Cloud': 'VMware',\n",
    "                                              'SAP Cloud': 'SAP',\n",
    "                                              'Salesforce Cloud': 'Salesforce',\n",
    "                                              'Alibaba Cloud': 'Alibaba',\n",
    "                                              'Tencent Cloud': 'Tencent'\n",
    "                                             })\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "\n",
    "df_count_cloud_2_year_later.plot(kind='bar',\n",
    "                                 ax=ax,\n",
    "                                color = ('#1f77b4', '#ff7f0e', '#d62728', '#2ca02c', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f','#7f7f7f', '#7f7f7f'))\n",
    "                                # Azure = Red = #d62728 // None = Green = #2ca02c\n",
    "ax.set_title(\"Cloud platform that respondant is willing to become more familiar in 2 year\", fontsize ='large', pad=20)\n",
    "ax.set_xlabel('Year', fontsize='medium', labelpad=20)\n",
    "ax.set_ylabel('Number of respondents', fontsize='medium', labelpad=20)\n",
    "ax.legend(bbox_to_anchor = (1.4, 0.8), fontsize=20)\n",
    "\n",
    "plt.savefig('1.4 Cloud platform that respondant is willing to become more familiar in 2 year.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cloud Computing PRODUCT ---\n",
    "\n",
    "# --- 2019 Q30 ---\n",
    "\n",
    "cloud_computing_2019 = ['Q30_Part_1','Q30_Part_2','Q30_Part_3','Q30_Part_4','Q30_Part_5','Q30_Part_6','Q30_Part_7','Q30_Part_8','Q30_Part_9','Q30_Part_10','Q30_Part_11','Q30_OTHER_TEXT']\n",
    "df_computing_2019 = pros_2019[cloud_computing_2019]\n",
    "count_compute_2019 = pd.Series(df_computing_2019[cloud_computing_2019].squeeze().values.ravel()).value_counts()\n",
    "\n",
    "# ---\n",
    "df_count_compute_2019 = pd.DataFrame(count_compute_2019)\n",
    "df_count_compute_2019 = df_count_compute_2019.reset_index()\n",
    "df_count_compute_2019.columns = ['Cloud Compute', 'Counts']\n",
    "\n",
    "# ---\n",
    "df_count_compute_2019['Cloud Compute'] = df_count_compute_2019['Cloud Compute'].str.strip()\n",
    "df_count_compute_2019 = df_count_compute_2019[(df_count_compute_2019['Cloud Compute'] == 'AWS Elastic Compute Cloud (EC2)') |\n",
    "                      (df_count_compute_2019['Cloud Compute'] == 'Google Compute Engine (GCE)') |\n",
    "                     (df_count_compute_2019['Cloud Compute'] == 'Azure Virtual Machines') |\n",
    "                     (df_count_compute_2019['Cloud Compute'] == 'None')\n",
    "                                             ]\n",
    "# ---\n",
    "df_count_compute_2019['Cloud Compute'] = df_count_compute_2019['Cloud Compute'].replace({\n",
    "                                                'AWS Elastic Compute Cloud (EC2)': 'Amazon Elastic Compute Cloud (EC2)',\n",
    "                                               'Google Compute Engine (GCE)': 'Google Cloud Compute Engine',\n",
    "                                                'Azure Virtual Machines': 'Microsoft Azure Virtual Machines',\n",
    "                                                'None': 'No / None'\n",
    "                                               })\n",
    "\n",
    "# --- 2020 Q27 ---\n",
    "cloud_computing_2020 = ['Q27_A_Part_1','Q27_A_Part_2','Q27_A_Part_3','Q27_A_Part_4','Q27_A_Part_5','Q27_A_Part_6','Q27_A_Part_7','Q27_A_Part_8','Q27_A_Part_9','Q27_A_Part_10','Q27_A_Part_11','Q27_A_OTHER']\n",
    "df_computing_2020 = pros_2020[cloud_computing_2020]\n",
    "count_compute_2020 = pd.Series(df_computing_2020[cloud_computing_2020].squeeze().values.ravel()).value_counts()\n",
    "# ---\n",
    "df_count_compute_2020 = pd.DataFrame(count_compute_2020)\n",
    "df_count_compute_2020 = df_count_compute_2020.reset_index()\n",
    "df_count_compute_2020.columns = ['Cloud Compute', 'Counts']\n",
    "# ---\n",
    "df_count_compute_2020['Cloud Compute'] = df_count_compute_2020['Cloud Compute'].str.strip()\n",
    "df_count_compute_2020 = df_count_compute_2020[(df_count_compute_2020['Cloud Compute'] == 'Amazon EC2') |\n",
    "                      (df_count_compute_2020['Cloud Compute'] == 'Google Cloud Compute Engine') |\n",
    "                     (df_count_compute_2020['Cloud Compute'] == 'Azure Cloud Services') |\n",
    "                     (df_count_compute_2020['Cloud Compute'] == 'No / None')\n",
    "                     ]\n",
    "# ---\n",
    "df_count_compute_2020['Cloud Compute'] = df_count_compute_2020['Cloud Compute'].replace({\n",
    "                                                'Amazon EC2': 'Amazon Elastic Compute Cloud (EC2)',\n",
    "                                               'Google Cloud Compute Engine': 'Google Cloud Compute Engine',\n",
    "                                                'Azure Cloud Services': 'Microsoft Azure Virtual Machines'\n",
    "                                               })\n",
    "\n",
    "\n",
    "\n",
    "# --- 2021 Q29 ---\n",
    "cloud_computing_2021 = ['Q29_A_Part_1','Q29_A_Part_2','Q29_A_Part_3','Q29_A_Part_4','Q29_A_OTHER']\n",
    "df_computing_2021 = pros_2021[cloud_computing_2021]\n",
    "count_compute_2021 = pd.Series(df_computing_2021[cloud_computing_2021].squeeze().values.ravel()).value_counts()\n",
    "# ---\n",
    "df_count_compute_2021 = pd.DataFrame(count_compute_2021)\n",
    "df_count_compute_2021 = df_count_compute_2021.reset_index()\n",
    "df_count_compute_2021.columns = ['Cloud Compute', 'Counts']\n",
    "# ---\n",
    "df_count_compute_2021['Cloud Compute'] = df_count_compute_2021['Cloud Compute'].str.strip()\n",
    "df_count_compute_2021 = df_count_compute_2021[(df_count_compute_2021['Cloud Compute'] != 'Other')]\n",
    "\n",
    "cloud_compute_df = df_count_2021.merge(df_count_2020, on = 'Cloud').merge(df_count_2019, how = 'left')\n",
    "cloud_compute_df = df_count_compute_2021.merge(df_count_compute_2020, on = 'Cloud Compute').merge(df_count_compute_2019, how = 'left')\n",
    "cloud_compute_df = cloud_compute_df.rename(columns = {'Cloud': 'Cloud', 'Counts_x':'2021', 'Counts_y': '2020', 'Counts': '2019'})\n",
    "\n",
    "cloud_compute_df = cloud_compute_df.T\n",
    "cloud_compute_df.columns = cloud_compute_df.iloc[0]\n",
    "cloud_compute_df = cloud_compute_df.drop(cloud_compute_df.index[0])\n",
    "#cloud_df.index.name = 'Cloud'\n",
    "cloud_compute_df = cloud_compute_df.iloc[::-1] # reverse ro\n",
    "\n",
    "# --- Plot ---\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "                      \n",
    "cloud_compute_df.plot(kind = 'bar', \n",
    "                      ax= ax,\n",
    "                      color = ('#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'))\n",
    "\n",
    "\n",
    "ax.set_title(\"Cloud platform product usage in regular basis in kaggle survey\", fontsize ='large', pad=20)\n",
    "ax.set_xlabel('Year', fontsize='medium', labelpad=20)\n",
    "ax.set_ylabel('Number of respondents', fontsize='medium', labelpad=20)\n",
    "ax.legend(bbox_to_anchor = (1.9, 0.5), fontsize=20)\n",
    "\n",
    "plt.savefig('1.6 Cloud platform product usage in regular basis in kaggle survey.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cloud computing product Market share ---\n",
    "\n",
    "for_perc = cloud_compute_df\n",
    "for_perc = for_perc.divide(for_perc.sum(axis=1), axis = 0)\n",
    "\n",
    "# --- Plot ---\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "                      \n",
    "for_perc.plot(kind='area', \n",
    "              stacked=True,\n",
    "              ax = ax,\n",
    "             color = ('#1f77b4', '#ff7f0e', '#2ca02c', '#d62728')\n",
    "             )\n",
    "\n",
    "ax.set_title(\"Cloud platform product usage by share\", fontsize ='large', pad=20)\n",
    "ax.set_xlabel('Year', fontsize='medium', labelpad=20)\n",
    "ax.set_ylabel('Percentage', fontsize='medium', labelpad=20)\n",
    "ax.legend(bbox_to_anchor = (1.9, 0.5), fontsize=20)\n",
    "\n",
    "plt.savefig('1.7 Cloud platform product usage by share.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2021 Q29_B Future preference ---\n",
    "\n",
    "cloud_computing_in_2 = ['Q29_B_Part_1','Q29_B_Part_2','Q29_B_Part_3','Q29_B_Part_4','Q29_B_OTHER']\n",
    "\n",
    "count_cloud_computing_in_2 = pd.Series(pros_2021[cloud_computing_in_2].squeeze().values.ravel()).value_counts()\n",
    "\n",
    "df_count_cloud_computing_in_2 = pd.DataFrame(count_cloud_computing_in_2)\n",
    "df_count_cloud_computing_in_2 = df_count_cloud_computing_in_2.reset_index()\n",
    "df_count_cloud_computing_in_2.columns = ['Cloud Compute', '2021']\n",
    "df_count_cloud_computing_in_2 = df_count_cloud_computing_in_2.set_index('Cloud Compute').T\n",
    "\n",
    "# -- Plot ---\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "df_count_cloud_computing_in_2.plot(kind = 'bar', \n",
    "                      ax= ax,\n",
    "                      color = ('#ff7f0e', '#d62728', '#1f77b4', '#2ca02c','#7f7f7f'))\n",
    "                    # Red = Google / Blue = Amazon / None = Green / Azure = Red\n",
    "\n",
    "ax.set_title(\"Cloud computing platform that willing to become more familiar in 2 year\", fontsize ='large', pad=20)\n",
    "ax.set_xlabel('Year', fontsize='medium', labelpad=20)\n",
    "ax.set_ylabel('Number of respondents', fontsize='medium', labelpad=20)\n",
    "ax.legend(bbox_to_anchor = (1.9, 0.5), fontsize=20)\n",
    "ax.text(0.01, 2500, 'AWS is pushed back to the third place',\n",
    "        verticalalignment='bottom',\n",
    "        fontsize=12)\n",
    "\n",
    "plt.savefig('1.8 Cloud computing platform that willing to become more familiar in 2 year.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2021 Q32 Big data ---\n",
    "\n",
    "big_data_2021 = ['Q32_A_Part_1','Q32_A_Part_2',\n",
    "                 'Q32_A_Part_3','Q32_A_Part_4',\n",
    "                 'Q32_A_Part_5','Q32_A_Part_6',\n",
    "                 'Q32_A_Part_7','Q32_A_Part_8',\n",
    "                 'Q32_A_Part_9','Q32_A_Part_10',\n",
    "                 'Q32_A_Part_11','Q32_A_Part_12',\n",
    "                 'Q32_A_Part_13','Q32_A_Part_14',\n",
    "                 'Q32_A_Part_15','Q32_A_Part_16',\n",
    "                 'Q32_A_Part_17','Q32_A_Part_18',\n",
    "                 'Q32_A_Part_19','Q32_A_Part_20','Q32_A_OTHER']\n",
    "\n",
    "df_bigdata_2021 = pros_2021[big_data_2021]\n",
    "count_bigdata_2021 = pd.Series(df_bigdata_2021[big_data_2021].squeeze().values.ravel()).value_counts()\n",
    "\n",
    "df_count_bigdata_2021 = pd.DataFrame(count_bigdata_2021)\n",
    "df_count_bigdata_2021 = df_count_bigdata_2021.reset_index()\n",
    "df_count_bigdata_2021.columns = ['big data', 'Counts']\n",
    "\n",
    "# --- 2020 Q29 Big data ---\n",
    "\n",
    "big_data_2020 = ['Q29_A_Part_1','Q29_A_Part_2',\n",
    "                 'Q29_A_Part_3','Q29_A_Part_4',\n",
    "                 'Q29_A_Part_5','Q29_A_Part_6',\n",
    "                 'Q29_A_Part_7','Q29_A_Part_8',\n",
    "                 'Q29_A_Part_9','Q29_A_Part_10',\n",
    "                 'Q29_A_Part_11','Q29_A_Part_12',\n",
    "                 'Q29_A_Part_13','Q29_A_Part_14',\n",
    "                 'Q29_A_Part_15','Q29_A_Part_16',\n",
    "                 'Q29_A_Part_17','Q29_A_OTHER']\n",
    "\n",
    "df_bigdata_2020 = pros_2020[big_data_2020]\n",
    "count_bigdata_2020 = pd.Series(df_bigdata_2020[big_data_2020].squeeze().values.ravel()).value_counts()\n",
    "\n",
    "df_count_bigdata_2020 = pd.DataFrame(count_bigdata_2020)\n",
    "df_count_bigdata_2020 = df_count_bigdata_2020.reset_index()\n",
    "df_count_bigdata_2020.columns = ['big data', 'Counts']\n",
    "\n",
    "# --- 2019 Q34 Big data ---\n",
    "\n",
    "big_data_2019 = ['Q34_Part_1','Q34_Part_2',\n",
    "                 'Q34_Part_3','Q34_Part_4',\n",
    "                 'Q34_Part_5','Q34_Part_6',\n",
    "                 'Q34_Part_7','Q34_Part_8',\n",
    "                 'Q34_Part_9','Q34_Part_10',\n",
    "                 'Q34_Part_11','Q34_Part_12',\n",
    "                 'Q34_OTHER_TEXT']\n",
    "\n",
    "df_bigdata_2019 = pros_2019[big_data_2019]\n",
    "count_bigdata_2019 = pd.Series(df_bigdata_2019[big_data_2019].squeeze().values.ravel()).value_counts()\n",
    "\n",
    "df_count_bigdata_2019 = pd.DataFrame(count_bigdata_2019)\n",
    "df_count_bigdata_2019 = df_count_bigdata_2019.reset_index()\n",
    "df_count_bigdata_2019.columns = ['big data', 'Counts']\n",
    "df_count_bigdata_2019 = df_count_bigdata_2019[(df_count_bigdata_2019['big data'] == 'MySQL') |\n",
    "                                              (df_count_bigdata_2019['big data'] == 'PostgresSQL') |\n",
    "                                              (df_count_bigdata_2019['big data'] == 'Microsoft SQL Server') |\n",
    "                                              (df_count_bigdata_2019['big data'] == 'SQLite') |\n",
    "                                              (df_count_bigdata_2019['big data'] == 'Oracle Database') |\n",
    "                                              (df_count_bigdata_2019['big data'] == 'AWS Relational Database Service') |\n",
    "                                              (df_count_bigdata_2019['big data'] == 'Microsoft Access') |\n",
    "                                              (df_count_bigdata_2019['big data'] == 'Google Cloud SQL') |\n",
    "                                              (df_count_bigdata_2019['big data'] == 'Azure SQL Database') |\n",
    "                                              (df_count_bigdata_2019['big data'] == 'AWS DynamoDB')\n",
    "                                             ]\n",
    "\n",
    "# --- 2021 Clean up. Merge into AWS, GCP, and AZURE // Open source and Commercial ---\n",
    "\n",
    "df_count_bigdata_2021['big data'] = df_count_bigdata_2021['big data'].str.strip()\n",
    "df_count_bigdata_2021['open source'] = df_count_bigdata_2021['big data'].apply(open_source)\n",
    "df_count_bigdata_2021['aws'] = df_count_bigdata_2021['big data'].apply(aws)\n",
    "df_count_bigdata_2021['gcp'] = df_count_bigdata_2021['big data'].apply(gcp)\n",
    "df_count_bigdata_2021['azure'] = df_count_bigdata_2021['big data'].apply(azure)\n",
    "\n",
    "open_source_2021 = df_count_bigdata_2021[df_count_bigdata_2021['open source'] == 1]\n",
    "open_source_2021 = open_source_2021[['big data', 'Counts']]\n",
    "\n",
    "aws_2021 = df_count_bigdata_2021[df_count_bigdata_2021['aws'] == 1]\n",
    "gcp_2021 = df_count_bigdata_2021[df_count_bigdata_2021['gcp'] == 1]\n",
    "azure_2021 = df_count_bigdata_2021[df_count_bigdata_2021['azure'] == 1]\n",
    "others_2021 = df_count_bigdata_2021[(df_count_bigdata_2021['aws'] != 1) & \n",
    "                                    (df_count_bigdata_2021['gcp'] != 1) & \n",
    "                                    (df_count_bigdata_2021['azure'] != 1) &\n",
    "                                    (df_count_bigdata_2021['open source'] != 1)]\n",
    "\n",
    "aws_2021['big data'].iloc[0] = 'aws'\n",
    "gcp_2021['big data'].iloc[0] = 'gcp'\n",
    "azure_2021['big data'].iloc[0] = 'azure'\n",
    "\n",
    "commercial_2021 = aws_2021.iloc[:1].append([gcp_2021.iloc[:1], azure_2021.iloc[:1], others_2021])\n",
    "to_drop = ['None', 'Other']\n",
    "commercial_2021 = commercial_2021[~commercial_2021['big data'].isin(to_drop)]\n",
    "commercial_2021 = commercial_2021[['big data', 'Counts']]\n",
    "\n",
    "open_source_2021 = open_source_2021.merge(commercial_2021, on = 'big data', how = 'outer')\n",
    "open_source_2021 = open_source_2021.rename(columns = {'Counts_x' : 'open source_2021', 'Counts_y' : 'commercial_2021'})\n",
    "\n",
    "open_source_2021 = open_source_2021.set_index('big data').T\n",
    "\n",
    "# --- 2020 Clean up. Merge into AWS, GCP, and AZURE // Open source and Commercial ---\n",
    "\n",
    "df_count_bigdata_2020['big data'] = df_count_bigdata_2020['big data'].str.strip()\n",
    "df_count_bigdata_2020['open source'] = df_count_bigdata_2020['big data'].apply(open_source)\n",
    "df_count_bigdata_2020['aws'] = df_count_bigdata_2020['big data'].apply(aws)\n",
    "df_count_bigdata_2020['gcp'] = df_count_bigdata_2020['big data'].apply(gcp)\n",
    "df_count_bigdata_2020['azure'] = df_count_bigdata_2020['big data'].apply(azure)\n",
    "\n",
    "open_source_2020 = df_count_bigdata_2020[df_count_bigdata_2020['open source'] == 1]\n",
    "open_source_2020 = open_source_2020[['big data', 'Counts']]\n",
    "\n",
    "aws_2020 = df_count_bigdata_2020[df_count_bigdata_2020['aws'] == 1]\n",
    "gcp_2020 = df_count_bigdata_2020[df_count_bigdata_2020['gcp'] == 1]\n",
    "azure_2020 = df_count_bigdata_2020[df_count_bigdata_2020['azure'] == 1]\n",
    "others_2020 = df_count_bigdata_2020[(df_count_bigdata_2020['aws'] != 1) & \n",
    "                                    (df_count_bigdata_2020['gcp'] != 1) & \n",
    "                                    (df_count_bigdata_2020['azure'] != 1) &\n",
    "                                    (df_count_bigdata_2020['open source'] != 1)]\n",
    "\n",
    "aws_2020['big data'].iloc[0] = 'aws'\n",
    "gcp_2020['big data'].iloc[0] = 'gcp'\n",
    "azure_2020['big data'].iloc[0] = 'azure'\n",
    "\n",
    "commercial_2020 = aws_2020.iloc[:1].append([gcp_2020.iloc[:1], azure_2020.iloc[:1], others_2020])\n",
    "to_drop = ['None', 'Other']\n",
    "commercial_2020 = commercial_2020[~commercial_2020['big data'].isin(to_drop)]\n",
    "commercial_2020 = commercial_2020[['big data', 'Counts']]\n",
    "\n",
    "open_source_2020 = open_source_2020.merge(commercial_2020, on = 'big data', how = 'outer')\n",
    "open_source_2020 = open_source_2020.rename(columns = {'Counts_x' : 'open source_2020', 'Counts_y' : 'commercial_2020'})\n",
    "\n",
    "open_source_2020 = open_source_2020.set_index('big data').T\n",
    "\n",
    "# --- 2019 Clean up. Merge into AWS, GCP, and AZURE // Open source and Commercial ---\n",
    "\n",
    "df_count_bigdata_2019['big data'] = df_count_bigdata_2019['big data'].str.strip()\n",
    "df_count_bigdata_2019['open source'] = df_count_bigdata_2019['big data'].apply(open_source)\n",
    "df_count_bigdata_2019['aws'] = df_count_bigdata_2019['big data'].apply(aws)\n",
    "df_count_bigdata_2019['gcp'] = df_count_bigdata_2019['big data'].apply(gcp)\n",
    "df_count_bigdata_2019['azure'] = df_count_bigdata_2019['big data'].apply(azure)\n",
    "\n",
    "open_source_2019 = df_count_bigdata_2019[df_count_bigdata_2019['open source'] == 1]\n",
    "open_source_2019 = open_source_2019[['big data', 'Counts']]\n",
    "\n",
    "aws_2019 = df_count_bigdata_2019[df_count_bigdata_2019['aws'] == 1]\n",
    "gcp_2019 = df_count_bigdata_2019[df_count_bigdata_2019['gcp'] == 1]\n",
    "azure_2019 = df_count_bigdata_2019[df_count_bigdata_2019['azure'] == 1]\n",
    "others_2019 = df_count_bigdata_2019[(df_count_bigdata_2019['aws'] != 1) & \n",
    "                                    (df_count_bigdata_2019['gcp'] != 1) & \n",
    "                                    (df_count_bigdata_2019['azure'] != 1) &\n",
    "                                    (df_count_bigdata_2019['open source'] != 1)]\n",
    "\n",
    "aws_2019['big data'].iloc[0] = 'aws'\n",
    "gcp_2019['big data'].iloc[0] = 'gcp'\n",
    "azure_2019['big data'].iloc[0] = 'azure'\n",
    "\n",
    "commercial_2019 = aws_2019.iloc[:1].append([gcp_2019.iloc[:1], azure_2019.iloc[:1], others_2019])\n",
    "to_drop = ['None', 'Other']\n",
    "commercial_2019 = commercial_2019[~commercial_2019['big data'].isin(to_drop)]\n",
    "commercial_2019 = commercial_2019[['big data', 'Counts']]\n",
    "\n",
    "open_source_2019 = open_source_2019.merge(commercial_2019, on = 'big data', how = 'outer')\n",
    "open_source_2019 = open_source_2019.rename(columns = {'Counts_x' : 'open source_2019', 'Counts_y' : 'commercial_2019'})\n",
    "\n",
    "open_source_2019 = open_source_2019.set_index('big data').T\n",
    "\n",
    "big_data_usage = pd.concat([open_source_2021, open_source_2020, open_source_2019])\n",
    "big_data_usage['PostgresSQL'] = big_data_usage['PostgresSQL'].fillna(big_data_usage['PostgreSQL'])\n",
    "big_data_usage = big_data_usage.drop(['PostgreSQL'], axis = 1)\n",
    "\n",
    "# --- Clean && Combine into Open / Commercial yearly ---\n",
    "\n",
    "big_data_usage[\"total\"] = big_data_usage.sum(axis=1)\n",
    "dummy_big_data = big_data_usage['total']\n",
    "dummy_big_data_2021 = dummy_big_data[:2]\n",
    "dummy_big_data_2020 = dummy_big_data[2:4]\n",
    "dummy_big_data_2019 = dummy_big_data[4:6]\n",
    "\n",
    "open_commercial_2021 = pd.DataFrame(dummy_big_data_2021)\n",
    "open_commercial_2021 = open_commercial_2021.rename(index = ({'open source_2021': 'open source', 'commercial_2021': 'commercial'}), columns=({'total': '2021'}))\n",
    "\n",
    "open_commercial_2020 = pd.DataFrame(dummy_big_data_2020)\n",
    "open_commercial_2020 = open_commercial_2020.rename(index = ({'open source_2020': 'open source', 'commercial_2020': 'commercial'}), columns=({'total': '2020'}))\n",
    "\n",
    "open_commercial_2019 = pd.DataFrame(dummy_big_data_2019)\n",
    "open_commercial_2019 = open_commercial_2019.rename(index = ({'open source_2019': 'open source', 'commercial_2019': 'commercial'}), columns=({'total': '2019'}))\n",
    "\n",
    "open_commercial_2021['2020'] = open_commercial_2020\n",
    "open_commercial_2021['2019'] = open_commercial_2019\n",
    "open_commercial_2021 = open_commercial_2021.iloc[:, ::-1]\n",
    "open_commercial_2021 = open_commercial_2021.T\n",
    "\n",
    "# --- Plot ---\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "open_commercial_2021.plot(kind = 'bar',\n",
    "                          stacked = True,\n",
    "                          ax=ax,\n",
    "                         color = ['#1f77b4', '#ff7f0e'])\n",
    "\n",
    "ax.set_title(\"Big data product usage\", fontsize ='large', pad=20)\n",
    "ax.set_xlabel('Year', fontsize='medium', labelpad=20)\n",
    "ax.set_ylabel('Number of respondents', fontsize='medium', labelpad=20)\n",
    "ax.legend(bbox_to_anchor = (1.4, 0.5), fontsize=20)\n",
    "\n",
    "plt.savefig('1.9 Big data product usage.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Big data Product market shares. Open vs. Commercial\n",
    "\n",
    "big_data_usage.drop(['total'], axis = 1, inplace = True)\n",
    "big_data_usage = big_data_usage.T\n",
    "\n",
    "big_data_usage_open_source = big_data_usage[['open source_2019', 'open source_2020', 'open source_2021']]\n",
    "big_data_usage_open_source.dropna(axis = 0, how = 'all', inplace = True)\n",
    "\n",
    "big_data_usage_commercial = big_data_usage[['commercial_2019', 'commercial_2020', 'commercial_2021']]\n",
    "big_data_usage_commercial = big_data_usage_commercial.rename({\n",
    "    'aws': 'AWS',\n",
    "    'gcp': 'GCP',\n",
    "    'azure': 'AZURE',\n",
    "    'Oracle Database': 'Oracle',\n",
    "    'Snowflake': 'Snowflake',\n",
    "    'IBM Db2': 'IBM'\n",
    "})\n",
    "big_data_usage_commercial.dropna(axis = 0, how = 'all', inplace = True)\n",
    "\n",
    "# --- Plot 3 pie charts twice for Open and Commerical ---\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (17,10))\n",
    "\n",
    "big_data_usage_open_source.plot.pie(subplots = True, \n",
    "                                    ax=ax, \n",
    "                                    legend = False,\n",
    "                                    xlabel = \"\", \n",
    "                                    ylabel =\"\", \n",
    "                                    autopct='%0.2f%%',\n",
    "                                   colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf'])\n",
    "plt.savefig('2.0 Open source Big data product usage share.png', bbox_inches='tight')\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (17,10))\n",
    "\n",
    "big_data_usage_commercial.plot.pie(subplots = True, \n",
    "                                   ax=ax, legend = False, \n",
    "                                   xlabel = \"\", \n",
    "                                   ylabel =\"\", \n",
    "                                   autopct='%0.2f%%',\n",
    "                                  colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf'])\n",
    "plt.savefig('2.1 Commercial Big data product usage share.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Business Intelligence Tools 2021 Q34 ---\n",
    "\n",
    "viz_2021 = ['Q34_A_Part_1','Q34_A_Part_2',\n",
    "                    'Q34_A_Part_3','Q34_A_Part_4',\n",
    "                    'Q34_A_Part_5','Q34_A_Part_6',\n",
    "                    'Q34_A_Part_7','Q34_A_Part_8',\n",
    "                    'Q34_A_Part_9','Q34_A_Part_10',\n",
    "                    'Q34_A_Part_11','Q34_A_Part_12',\n",
    "                    'Q34_A_Part_13','Q34_A_Part_14',\n",
    "                    'Q34_A_Part_15','Q34_A_Part_16','Q34_A_OTHER']\n",
    "df_viz_2021 = pd.Series(pros_2021[viz_2021].squeeze().values.ravel()).value_counts()\n",
    "\n",
    "df_count_viz_2021 = pd.DataFrame(df_viz_2021)\n",
    "df_count_viz_2021 = df_count_viz_2021.reset_index()\n",
    "df_count_viz_2021.columns = ['BI tools', '2021']\n",
    "\n",
    "df_count_viz_2021 = df_count_viz_2021[1:] # Drop None\n",
    "\n",
    "# --- Business Intelligence Tools 2020 Q31 ---\n",
    "\n",
    "viz_2020 = ['Q31_A_Part_1','Q31_A_Part_2',\n",
    "              'Q31_A_Part_3','Q31_A_Part_4',\n",
    "              'Q31_A_Part_5','Q31_A_Part_6',\n",
    "              'Q31_A_Part_7','Q31_A_Part_8',\n",
    "              'Q31_A_Part_9','Q31_A_Part_10',\n",
    "              'Q31_A_Part_11','Q31_A_Part_12',\n",
    "              'Q31_A_Part_13','Q31_A_Part_14','Q31_A_OTHER']\n",
    "df_viz_2020 = pd.Series(pros_2020[viz_2020].squeeze().values.ravel()).value_counts()\n",
    "\n",
    "df_count_viz_2020 = pd.DataFrame(df_viz_2020)\n",
    "df_count_viz_2020 = df_count_viz_2020.reset_index()\n",
    "df_count_viz_2020.columns = ['BI tools', '2020']\n",
    "\n",
    "df_count_viz_2020 = df_count_viz_2020[1:] # Drop None\n",
    "\n",
    "merged_viz = df_count_viz_2021.set_index('BI tools').combine_first(df_count_viz_2020.set_index('BI tools'))\n",
    "merged_viz = merged_viz.sort_values(by=['2021'], ascending = False)\n",
    "\n",
    "# --- Merged ---\n",
    "\n",
    "merged_viz['2021'].iloc[0] = merged_viz['2021'].iloc[0] + merged_viz['2021'].iloc[6] # Tableau + Tableau CRM\n",
    "merged_viz['2020'].iloc[4] = merged_viz['2020'].iloc[4] + merged_viz['2020'].iloc[16] # Salesforce + Einstein Analytics\n",
    "merged_viz['2021'].iloc[1] = merged_viz['2021'].iloc[1] + merged_viz['2021'].iloc[7]\n",
    "\n",
    "merged_viz = merged_viz.drop(merged_viz.index[[6,7,16]])[:-1]\n",
    "merged_viz = merged_viz.T\n",
    "\n",
    "# --- plot ---\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "\n",
    "merged_viz.plot(kind = 'bar',\n",
    "                ax=ax,\n",
    "                color = ('#1f77b4', '#ff7f0e', '#d62728', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#17becf', '#7f7f7f','#7f7f7f', '#7f7f7f'))\n",
    "\n",
    "ax.set_title(\"Commerical Business Intelligence tool usage by professionals in kaggle survey\", fontsize ='large', pad=20)\n",
    "ax.set_xlabel('Year', fontsize='medium', labelpad=20)\n",
    "ax.set_ylabel('Number of respondents', fontsize='medium', labelpad=20)\n",
    "ax.legend(bbox_to_anchor = (1.4, 0.8), fontsize=20)\n",
    "\n",
    "plt.savefig('3.1 Commerical Business Intelligence tool usage by professionals in kaggle survey.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Pct Change ---\n",
    "merged_viz_perc = merged_viz.pct_change(periods = 1)[1:]\n",
    "\n",
    "# pct_change\n",
    "data_bi_growth = pd.DataFrame()\n",
    "data_bi_growth['total'] = merged_viz.sum(axis=1)\n",
    "data_bi_growth = data_bi_growth.pct_change(periods = 1)\n",
    "\n",
    "avg_growth_merged_2021 = round(data_bi_growth.iloc[1].mean(),2) # avg growth rate\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "\n",
    "merged_viz_perc.plot(kind = 'bar',\n",
    "                ax=ax,\n",
    "                color = ('#1f77b4', '#ff7f0e', '#d62728', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#17becf', '#7f7f7f','#7f7f7f', '#7f7f7f'))\n",
    "\n",
    "ax.set_title(\"Commerical Business Intelligence growth rate compare to previous year\", fontsize ='large', pad=20)\n",
    "ax.set_xlabel('Year', fontsize='medium', labelpad=20)\n",
    "ax.set_ylabel('Number of respondents', fontsize='medium', labelpad=20)\n",
    "ax.legend(bbox_to_anchor = (1.4, 0.8), fontsize=20)\n",
    "\n",
    "plt.axhline(y=avg_growth_merged_2021, xmin=0.2, xmax= 0.7, color='black', linestyle='dotted', linewidth=5)\n",
    "\n",
    "ax.text(-0.495, 0.52, 'Average growth rate ' +str(avg_growth_merged_2021*100) + '%')\n",
    "\n",
    "plt.savefig('3.2 Commerical Business Intelligence growth rate compare to previous year.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Python vizualization library ---\n",
    "\n",
    "# --- Q14 2020 ---\n",
    "\n",
    "viz_bi_2020 =['Q14_Part_1','Q14_Part_2',\n",
    "              'Q14_Part_3','Q14_Part_4',\n",
    "              'Q14_Part_5','Q14_Part_6',\n",
    "              'Q14_Part_7','Q14_Part_8',\n",
    "              'Q14_Part_9','Q14_Part_10',\n",
    "              'Q14_Part_11','Q14_OTHER',\n",
    "              'Q31_A_Part_1','Q31_A_Part_2',\n",
    "              'Q31_A_Part_3','Q31_A_Part_4',\n",
    "              'Q31_A_Part_5','Q31_A_Part_6',\n",
    "              'Q31_A_Part_7','Q31_A_Part_8',\n",
    "              'Q31_A_Part_9','Q31_A_Part_10',\n",
    "              'Q31_A_Part_11','Q31_A_Part_12',\n",
    "              'Q31_A_Part_13','Q31_A_Part_14','Q31_A_OTHER']\n",
    "\n",
    "lib_BI_2020 = pros_2020[viz_bi_2020].rename(columns ={\n",
    "    'Q14_Part_1': 'Matplotlib',\n",
    "    'Q14_Part_2': 'Seaborn',\n",
    "    'Q14_Part_3': 'Plotly',\n",
    "    'Q14_Part_4': 'Ggplot',\n",
    "    'Q14_Part_5': 'Shiny',\n",
    "    'Q14_Part_6': 'D3 js',\n",
    "    'Q14_Part_7': 'Altair',\n",
    "    'Q14_Part_8': 'Bokeh',\n",
    "    'Q14_Part_9': 'Geoplotlib',\n",
    "    'Q14_Part_10': 'Leaflet',\n",
    "    'Q14_Part_11': 'None',\n",
    "    'Q14_OTHER': 'Other',\n",
    "    \n",
    "    'Q31_A_Part_1': 'Amazon QuickSight',\n",
    "    'Q31_A_Part_2': 'MS Power BI',\n",
    "    'Q31_A_Part_3': 'Google Data Studio',\n",
    "    'Q31_A_Part_4': 'Looker',\n",
    "    'Q31_A_Part_5': 'Tableau',\n",
    "    'Q31_A_Part_6': 'Salesforce',\n",
    "    'Q31_A_Part_7': 'Einstein Analytics',\n",
    "    'Q31_A_Part_8': 'Qlik',\n",
    "    'Q31_A_Part_9': 'Domo',\n",
    "    'Q31_A_Part_10': 'TIBCO',\n",
    "    'Q31_A_Part_11': 'Alteryx',\n",
    "    'Q31_A_Part_12': 'Sisense',\n",
    "    'Q31_A_Part_13': 'SAP',\n",
    "    'Q31_A_Part_14': 'None',\n",
    "    'Q31_A_OTHER': 'Other'\n",
    "})\n",
    "\n",
    "lib_2020 = ['Matplotlib',\n",
    "    'Seaborn',\n",
    "    'Plotly',\n",
    "    'Ggplot']\n",
    "\n",
    "BI_2020 = ['Amazon QuickSight',\n",
    "    'MS Power BI',\n",
    "    'Google Data Studio',\n",
    "    'Looker',\n",
    "    'Tableau',\n",
    "    'Salesforce',\n",
    "    'Einstein Analytics',\n",
    "    'Qlik',\n",
    "    'Domo',\n",
    "    'TIBCO',\n",
    "    'Alteryx',\n",
    "    'Sisense',\n",
    "    'SAP'\n",
    "    ]\n",
    "# ----- library growth -----\n",
    "\n",
    "data_viz_li_2019 = ['Q20_Part_1',\n",
    "                    'Q20_Part_2',\n",
    "                    'Q20_Part_3',\n",
    "                    'Q20_Part_4',\n",
    "                    'Q20_Part_5',\n",
    "                    'Q20_Part_6',\n",
    "                    'Q20_Part_7',\n",
    "                    'Q20_Part_8',\n",
    "                    'Q20_Part_9',\n",
    "                    'Q20_Part_10',\n",
    "                    'Q20_Part_11',\n",
    "                    'Q20_Part_12']\n",
    "\n",
    "df_data_viz_li_2019 = pros_2019[data_viz_li_2019]\n",
    "\n",
    "\n",
    "count_data_viz_li_2019 = pd.Series(df_data_viz_li_2019[data_viz_li_2019].squeeze().values.ravel()).value_counts()\n",
    "#count_bigdata_2020\n",
    "\n",
    "df_count_data_viz_li_2019 = pd.DataFrame(count_data_viz_li_2019)\n",
    "df_count_data_viz_li_2019 = df_count_data_viz_li_2019.reset_index()\n",
    "df_count_data_viz_li_2019.columns = ['lib', 'Counts']\n",
    "df_count_data_viz_li_2019\n",
    "\n",
    "\n",
    "data_viz_li_2020 =['Q14_Part_1','Q14_Part_2',\n",
    "              'Q14_Part_3','Q14_Part_4',\n",
    "              'Q14_Part_5','Q14_Part_6',\n",
    "              'Q14_Part_7','Q14_Part_8',\n",
    "              'Q14_Part_9','Q14_Part_10',\n",
    "              'Q14_Part_11','Q14_OTHER']\n",
    "\n",
    "df_data_viz_li_2020 = pros_2020[data_viz_li_2020]\n",
    "\n",
    "\n",
    "count_data_viz_li_2020 = pd.Series(df_data_viz_li_2020[data_viz_li_2020].squeeze().values.ravel()).value_counts()\n",
    "#count_bigdata_2020\n",
    "\n",
    "df_count_data_viz_li_2020 = pd.DataFrame(count_data_viz_li_2020)\n",
    "df_count_data_viz_li_2020 = df_count_data_viz_li_2020.reset_index()\n",
    "df_count_data_viz_li_2020.columns = ['lib', 'Counts']\n",
    "df_count_data_viz_li_2020\n",
    "\n",
    "viz_bi_2021 = ['Q14_Part_1','Q14_Part_2',\n",
    "                         'Q14_Part_3','Q14_Part_4',\n",
    "                         'Q14_Part_5','Q14_Part_6',\n",
    "                         'Q14_Part_7','Q14_Part_8',\n",
    "                         'Q14_Part_9','Q14_Part_10',\n",
    "                         'Q14_Part_11','Q14_OTHER']\n",
    "\n",
    "df_data_viz_li_2021 = pros_2021[viz_bi_2021]\n",
    "\n",
    "\n",
    "count_data_viz_li_2021 = pd.Series(df_data_viz_li_2021[viz_bi_2021].squeeze().values.ravel()).value_counts()\n",
    "#count_bigdata_2020\n",
    "\n",
    "df_count_data_viz_li_2021 = pd.DataFrame(count_data_viz_li_2021)\n",
    "df_count_data_viz_li_2021 = df_count_data_viz_li_2021.reset_index()\n",
    "df_count_data_viz_li_2021.columns = ['lib', 'Counts']\n",
    "\n",
    "# ---------------\n",
    "\n",
    "df_count_data_viz_li_2021 = df_count_data_viz_li_2021.merge(df_count_data_viz_li_2020, on = 'lib', how = 'outer')\n",
    "df_count_data_viz_li_2021 = df_count_data_viz_li_2021.merge(df_count_data_viz_li_2019, on = 'lib', how = 'outer')\n",
    "df_count_data_viz_li_2021 = df_count_data_viz_li_2021.rename(columns = {'Counts_x' : '2021 ', 'Counts_y' : '2020', 'Counts': '2019'})\n",
    "df_count_data_viz_li_2021.at[8,'lib'] = 'D3.js'\n",
    "df_count_data_viz_li_2021.at[8,'2019'] = df_count_data_viz_li_2021.at[12,'2019']\n",
    "df_count_data_viz_li_2021 = df_count_data_viz_li_2021[:-1]\n",
    "df_count_data_viz_li_2021 = df_count_data_viz_li_2021.set_index('lib').T\n",
    "df_count_data_viz_li_2021 = df_count_data_viz_li_2021[::-1]\n",
    "df_count_data_viz_li_2021 = df_count_data_viz_li_2021.drop(columns = ['None'])\n",
    "\n",
    "# --- Plot ---\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "df_count_data_viz_li_2021.plot(kind='bar', \n",
    "                               ax = ax,\n",
    "                              color = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "                              )\n",
    "\n",
    "ax.set_title(\"Visualization Library usage by professionals in kaggle survey\", fontsize ='large', pad=20)\n",
    "ax.set_xlabel('Year', fontsize='medium', labelpad=20)\n",
    "ax.set_ylabel('Number of respondents', fontsize='medium', labelpad=20)\n",
    "ax.legend(bbox_to_anchor = (1.4, 0.8), fontsize=20)\n",
    "\n",
    "plt.savefig('3.3 Visualization Library usage by professionals in kaggle survey.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Library growth ---\n",
    "\n",
    "df_count_data_viz_li_2021_perc = df_count_data_viz_li_2021.pct_change(periods = 1)[1:]\n",
    "\n",
    "# pct_change\n",
    "data_viz_growth = pd.DataFrame()\n",
    "data_viz_growth['total'] = df_count_data_viz_li_2021.sum(axis=1)\n",
    "data_viz_growth_perc = data_viz_growth.pct_change(periods = 1)\n",
    "\n",
    "avg_growth_2020 = round(data_viz_growth_perc.iloc[1].mean(),2)\n",
    "avg_growth_2021 = round(data_viz_growth_perc.iloc[2].mean(),2)\n",
    "\n",
    "# --- Plot ---\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "df_count_data_viz_li_2021_perc.plot(kind = 'bar', \n",
    "                                    ax=ax,\n",
    "                                   color = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf'])\n",
    "\n",
    "ax.set_title(\"Visualization library usage growth rate compare to previous year\", fontsize ='large', pad=20)\n",
    "ax.set_xlabel('Year', fontsize='medium', labelpad=20)\n",
    "ax.set_ylabel('Number of respondents', fontsize='medium', labelpad=20)\n",
    "ax.legend(bbox_to_anchor = (1.6, 0.8), fontsize=20)\n",
    "\n",
    "plt.axhline(y=0, xmin=-1, xmax= 2, color='red', linestyle='dotted', linewidth=5)\n",
    "plt.axhline(y=avg_growth_2020, xmin=0.05, xmax= 0.45, color='black', linestyle='dotted', linewidth=5)\n",
    "plt.axhline(y=avg_growth_2021, xmin=0.55, xmax= 0.95, color='black', linestyle='dotted', linewidth=5)\n",
    "\n",
    "plt.rc('font', size=16)\n",
    "\n",
    "ax.text(0.26, 0.08, 'Avg growth rate ' +str(avg_growth_2020*100) + '%')\n",
    "ax.text(0.25, 0.35, 'Avg growth rate '+ str(avg_growth_2021*100) + '%')\n",
    "\n",
    "plt.savefig('3.4 Visualization library usage growth rate compare to previous year.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.rcParams['font.size'] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Machine learning tools ---\n",
    "# --- Google cloud Speect-to-Text, Google Cloud Natural Language, Google Cloud Vision, Google Cloud Translation are assumed under Google Vertex AI ---\n",
    "\n",
    "# --- 2019 Q32 ML tools ---\n",
    "\n",
    "ml_product_2019 = ['Q32_Part_1','Q32_Part_2','Q32_Part_3','Q32_Part_4','Q32_Part_5','Q32_Part_6','Q32_Part_7','Q32_Part_8','Q32_Part_9','Q32_Part_10','Q32_Part_11','Q32_Part_12']\n",
    "df_ml_product_2019 = pros_2019[ml_product_2019]\n",
    "count_ml_product_2019 = pd.Series(df_ml_product_2019[ml_product_2019].squeeze().values.ravel()).value_counts()\n",
    "\n",
    "df_count_ml_2019 = pd.DataFrame(count_ml_product_2019)\n",
    "df_count_ml_2019 = df_count_ml_2019.reset_index()\n",
    "df_count_ml_2019.columns = ['ML engine', 'Counts']\n",
    "\n",
    "# --- 2020 Q28 ML tools ---\n",
    "\n",
    "ml_product_2020 = ['Q28_A_Part_1','Q28_A_Part_2','Q28_A_Part_3','Q28_A_Part_4','Q28_A_Part_5','Q28_A_Part_6','Q28_A_Part_7','Q28_A_Part_8','Q28_A_Part_9','Q28_A_Part_10']\n",
    "df_ml_product_2020 = pros_2020[ml_product_2020]\n",
    "count_ml_product_2020 = pd.Series(df_ml_product_2020[ml_product_2020].squeeze().values.ravel()).value_counts()\n",
    "\n",
    "df_count_ml_2020 = pd.DataFrame(count_ml_product_2020)\n",
    "df_count_ml_2020 = df_count_ml_2020.reset_index()\n",
    "df_count_ml_2020.columns = ['ML engine', 'Counts']\n",
    "\n",
    "# --- 2021 Q31 ML tools ---\n",
    "\n",
    "ml_product_2021 = ['Q31_A_Part_1','Q31_A_Part_2','Q31_A_Part_3','Q31_A_Part_4','Q31_A_Part_5','Q31_A_Part_6','Q31_A_Part_7','Q31_A_Part_8','Q31_A_Part_9','Q31_A_OTHER']\n",
    "df_ml_product_2021 = pros_2021[ml_product_2021]\n",
    "count_ml_product_2021 = pd.Series(df_ml_product_2021[ml_product_2021].squeeze().values.ravel()).value_counts()\n",
    "\n",
    "df_count_ml_2021 = pd.DataFrame(count_ml_product_2021)\n",
    "df_count_ml_2021 = df_count_ml_2021.reset_index()\n",
    "df_count_ml_2021.columns = ['ML engine', 'Counts']\n",
    "\n",
    "# --- Products are merged into one big category ---\n",
    "\n",
    "# ex1) google vision, google NLP - > Google Cloud Vertex AI\n",
    "# ex2) Amazon forecast, recognition - > Amazon SageMaker\n",
    "\n",
    "df_count_ml_2019 = df_count_ml_2019.drop(df_count_ml_2019.index[[0,5,7,8,9,11]])\n",
    "\n",
    "df_count_ml_2020 = df_count_ml_2020.drop(df_count_ml_2020.index[[0,4,5,6,7,8,9]])\n",
    "\n",
    "df_count_ml_2021 = df_count_ml_2021.drop(df_count_ml_2021.index[[0, 7]])\n",
    "\n",
    "engine_df = df_count_ml_2021.merge(df_count_ml_2020, on = 'ML engine', how = 'outer').merge(df_count_ml_2019, how = 'outer')\n",
    "engine_df = engine_df.rename(columns = {'Counts_x' : '2021', 'Counts_y' : '2020', 'Counts' : '2019'})\n",
    "engine_df['ML engine'] = engine_df['ML engine'].str.strip()\n",
    "engine_df.at[8, 'ML engine'] = 'Google Cloud Vertex AI'\n",
    "engine_df.at[9, 'ML engine'] = 'Google Cloud Vertex AI'\n",
    "engine_df = engine_df.groupby(['ML engine']).sum()\n",
    "engine_df = engine_df.sort_values(by=['2021'], ascending = False).reset_index()\n",
    "\n",
    "engine_df = engine_df.set_index('ML engine').T[::-1]\n",
    "columns_clean = ['Amazon SageMaker','Azure Machine Learning Studio','Databricks','Google Cloud Vertex AI','DataRobot','Rapidminer','Alteryx','Dataiku']\n",
    "engine_df = engine_df[columns_clean]\n",
    "\n",
    "dummy_df = engine_df[['Amazon SageMaker','Azure Machine Learning Studio','Google Cloud Vertex AI']]\n",
    "dummy_df['multiplier'] = None\n",
    "dummy_df['multiplier'] = dummy_df.sum(axis=1).pct_change(periods = 1)\n",
    "growth_multiplier_2020 = dummy_df['multiplier'].iloc[1]\n",
    "growth_multiplier_2021 = dummy_df['multiplier'].iloc[2]\n",
    "\n",
    "for col in ['Databricks', 'DataRobot', 'Rapidminer', 'Alteryx', 'Dataiku']:\n",
    "    engine_df[col].iloc[1] = engine_df[col].iloc[2]/(1+growth_multiplier_2021)\n",
    "    engine_df[col].iloc[0] = engine_df[col].iloc[1]/(1+growth_multiplier_2020)\n",
    "\n",
    "engine_df = engine_df.round(0)\n",
    "\n",
    "# --- Plot ---\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "\n",
    "engine_df.plot(kind = 'bar',\n",
    "                ax=ax,\n",
    "                color = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f'])\n",
    "\n",
    "ax.set_title(\"Managed ML product usage on regular basis\", fontsize ='large', pad=20)\n",
    "ax.set_xlabel('Year', fontsize='medium', labelpad=20)\n",
    "ax.set_ylabel('Number of respondents', fontsize='medium', labelpad=20)\n",
    "ax.legend(bbox_to_anchor = (1.8, 0.6), fontsize=20)\n",
    "ax.text(2, 740, 'Google pushed back')\n",
    "ax.text(1, 740, 'Google led')\n",
    "\n",
    "plt.annotate('* The number of Databricks, Datarobot, RapidMiner, Alteryx and Dataiku in 2019 and 2020 were derived from the yearly avg industry growth', \n",
    "             (0,0), \n",
    "             (-50,-95), \n",
    "             fontsize=8, \n",
    "             xycoords='axes fraction', \n",
    "             textcoords='offset points', va='top')\n",
    "\n",
    "\n",
    "plt.annotate(\"* Google vertex AI is launched in 2021. Google vertex AI in 2019 and 2020 is the sum of google's listed products. This applies to AWS and Azure too\", \n",
    "             (0,0), \n",
    "             (-50,-105), \n",
    "             fontsize=8, \n",
    "             xycoords='axes fraction', \n",
    "             textcoords='offset points', va='top')\n",
    "\n",
    "plt.savefig('4.1 Managed ML product usage on regular basis.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "managed_ml_2021_2_year = ['Q31_B_Part_1','Q31_B_Part_2',\n",
    "                          'Q31_B_Part_3','Q31_B_Part_4',\n",
    "                          'Q31_B_Part_5','Q31_B_Part_6',\n",
    "                          'Q31_B_Part_7','Q31_B_Part_8',\n",
    "                          'Q31_B_Part_9','Q31_B_OTHER']\n",
    "\n",
    "df_managed_ml_2021_2_year = pros_2021[managed_ml_2021_2_year]\n",
    "\n",
    "count_managed_ml_2021_2_year = pd.Series(df_managed_ml_2021_2_year[managed_ml_2021_2_year].squeeze().values.ravel()).value_counts()\n",
    "\n",
    "df_count_managed_ml_2021_2_year = pd.DataFrame(count_managed_ml_2021_2_year)\n",
    "df_count_managed_ml_2021_2_year = df_count_managed_ml_2021_2_year.reset_index()\n",
    "df_count_managed_ml_2021_2_year.columns = ['Managed ML', '2021']\n",
    "df_count_managed_ml_2021_2_year = df_count_managed_ml_2021_2_year.set_index('Managed ML').T\n",
    "df_count_managed_ml_2021_2_year.columns = df_count_managed_ml_2021_2_year.columns.str.strip()\n",
    "df_count_managed_ml_2021_2_year = df_count_managed_ml_2021_2_year[['Amazon SageMaker','Azure Machine Learning Studio',\n",
    "                                 'Google Cloud Vertex AI','Databricks', 'DataRobot', 'Rapidminer', 'Alteryx', 'Dataiku']]\n",
    "df_count_managed_ml_2021_2_year = df_count_managed_ml_2021_2_year.T.sort_values(by= '2021', ascending = False).T\n",
    "\n",
    "# --- Plot ---\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "\n",
    "df_count_managed_ml_2021_2_year.plot(kind = 'bar',\n",
    "                ax=ax,\n",
    "                color = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f', '#7f7f7f'])\n",
    "\n",
    "ax.set_title(\"Willingness to become more familiar in the next 2 years\", fontsize ='large', pad=20)\n",
    "ax.set_xlabel('Year', fontsize='medium', labelpad=20)\n",
    "ax.set_ylabel('Number of respondents', fontsize='medium', labelpad=20)\n",
    "ax.legend(bbox_to_anchor = (1.8, 0.6), fontsize=20)\n",
    "ax.text(-0.42, 2350, 'Google is back to 1st, Azure just behind')\n",
    "\n",
    "plt.savefig('4.2 Willingness to become more familiar in the next 2 years.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- AutoML ---\n",
    "\n",
    "# --- 2021 Q21 AutoML---\n",
    "\n",
    "autoML_2021 = ['Q37_A_Part_1','Q37_A_Part_2','Q37_A_Part_3','Q37_A_Part_4','Q37_A_Part_5','Q37_A_Part_6','Q37_A_Part_7','Q37_A_OTHER']\n",
    "df_autoML_2021 = pros_2021[autoML_2021]\n",
    "count_autoML_2021 = pd.Series(df_autoML_2021[autoML_2021].squeeze().values.ravel()).value_counts()\n",
    "\n",
    "df_count_autoML_2021 = pd.DataFrame(count_autoML_2021)\n",
    "df_count_autoML_2021 = df_count_autoML_2021.reset_index()\n",
    "df_count_autoML_2021.columns = ['AutoML', 'Counts']\n",
    "\n",
    "# --- 2020 Q34 AutoML---\n",
    "\n",
    "autoML_2020 = ['Q34_A_Part_1','Q34_A_Part_2','Q34_A_Part_3','Q34_A_Part_4','Q34_A_Part_5','Q34_A_Part_6','Q34_A_Part_7','Q34_A_Part_8','Q34_A_Part_9','Q34_A_Part_10','Q34_A_Part_11','Q34_A_OTHER']\n",
    "df_autoML_2020 = pros_2020[autoML_2020]\n",
    "count_autoML_2020 = pd.Series(df_autoML_2020[autoML_2020].squeeze().values.ravel()).value_counts()\n",
    "\n",
    "df_count_autoML_2020 = pd.DataFrame(count_autoML_2020)\n",
    "df_count_autoML_2020 = df_count_autoML_2020.reset_index()\n",
    "df_count_autoML_2020.columns = ['AutoML', 'Counts']\n",
    "\n",
    "# --- 2019 Q33 AutoML---\n",
    "\n",
    "autoML_2019 = ['Q33_Part_1','Q33_Part_2','Q33_Part_3','Q33_Part_4','Q33_Part_5','Q33_Part_6','Q33_Part_7','Q33_Part_8','Q33_Part_9','Q33_Part_10','Q33_Part_11','Q33_Part_12']\n",
    "df_autoML_2019 = pros_2019[autoML_2019]\n",
    "count_autoML_2019 = pd.Series(df_autoML_2019[autoML_2019].squeeze().values.ravel()).value_counts()\n",
    "\n",
    "df_count_autoML_2019 = pd.DataFrame(count_autoML_2019)\n",
    "df_count_autoML_2019 = df_count_autoML_2019.reset_index()\n",
    "df_count_autoML_2019.columns = ['AutoML', 'Counts']\n",
    "\n",
    "# --- AutoML merged ---\n",
    "\n",
    "autoML_df = df_count_autoML_2021.merge(df_count_autoML_2020, on = 'AutoML', how = 'outer').merge(df_count_autoML_2019, how = 'outer')\n",
    "autoML_df = autoML_df.rename(columns = {'Counts_x' : '2021', 'Counts_y' : '2020', 'Counts' : '2019'})\n",
    "autoML_df = autoML_df.drop(autoML_df.index[[0,7,8,9,10,12,13,14,15]])\n",
    "autoML_df.at[16, 'AutoML'] = 'Google Cloud AutoML'\n",
    "autoML_df.at[11, 'AutoML'] = 'H2O Driverless AI'\n",
    "autoML_df['AutoML'] = autoML_df['AutoML'].str.strip()\n",
    "autoML_df = autoML_df.groupby(['AutoML']).sum()\n",
    "autoML_df = autoML_df.sort_values(by=['2021'], ascending = False)\n",
    "\n",
    "autoML_df = autoML_df.T\n",
    "autoML_df = autoML_df[::-1]\n",
    "\n",
    "dummy_df = autoML_df[['DataRobot AutoML','Databricks AutoML','Google Cloud AutoML','H2O Driverless AI']]\n",
    "dummy_df['total'] = dummy_df.sum(axis=1)\n",
    "dummy_df['total'] = dummy_df['total'].pct_change(periods=1)\n",
    "autoML_growth_2020 = dummy_df['total'].iloc[1]\n",
    "autoML_growth_2021 = dummy_df['total'].iloc[2]\n",
    "\n",
    "sage_azure = ['Amazon Sagemaker Autopilot', 'Azure Automated Machine Learning']\n",
    "\n",
    "for col in sage_azure:\n",
    "    autoML_df[col].iloc[1] = autoML_df[col].iloc[2]/(1+autoML_growth_2021)\n",
    "    autoML_df[col].iloc[0] = autoML_df[col].iloc[1]/(1+autoML_growth_2020)\n",
    "    \n",
    "autoML_df = autoML_df.round(0)\n",
    "\n",
    "# --- Plot ---\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "\n",
    "autoML_df.plot(kind = 'bar',\n",
    "                ax=ax,\n",
    "                color = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf'])\n",
    "\n",
    "ax.set_title(\"AutoML usage from 2019 to 2021\", fontsize ='large', pad=20)\n",
    "ax.set_xlabel('Year', fontsize='medium', labelpad=20)\n",
    "ax.set_ylabel('Number of respondents', fontsize='medium', labelpad=20)\n",
    "ax.legend(bbox_to_anchor = (1.8, 0.6), fontsize=20)\n",
    "\n",
    "plt.annotate('* Numbers in Amazon Sagemaker Autopilot and Azure Automated Machine Learning in 2019 and 2020 were derived from the yearly avg industry growth', \n",
    "             (0,0), \n",
    "             (-50,-95), \n",
    "             fontsize=8, \n",
    "             xycoords='axes fraction', \n",
    "             textcoords='offset points', va='top')\n",
    "\n",
    "plt.savefig('5.1 AutoML usage from 2019 to 2021.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- AutoML future Preference ---\n",
    "\n",
    "# --- 2021 Q31 AutoML ---\n",
    "\n",
    "managed_ml_2021_2_year = ['Q31_B_Part_1','Q31_B_Part_2',\n",
    "                          'Q31_B_Part_3','Q31_B_Part_4',\n",
    "                          'Q31_B_Part_5','Q31_B_Part_6',\n",
    "                          'Q31_B_Part_7','Q31_B_Part_8',\n",
    "                          'Q31_B_Part_9','Q31_B_OTHER']\n",
    "\n",
    "automl_in_2 = ['Q37_B_Part_1',\n",
    "               'Q37_B_Part_2',\n",
    "               'Q37_B_Part_3',\n",
    "               'Q37_B_Part_4',\n",
    "               'Q37_B_Part_5',\n",
    "               'Q37_B_Part_6',\n",
    "               'Q37_B_Part_7',\n",
    "               'Q37_B_OTHER']\n",
    "\n",
    "df_automl_in_2 = pros_2021[automl_in_2]\n",
    "\n",
    "count_df_automl_in_2 = pd.Series(df_automl_in_2[automl_in_2].squeeze().values.ravel()).value_counts()\n",
    "\n",
    "df_count_df_automl_in_2 = pd.DataFrame(count_df_automl_in_2)\n",
    "df_count_df_automl_in_2 = df_count_df_automl_in_2.reset_index()\n",
    "df_count_df_automl_in_2.columns = ['Auto ML', '2021']\n",
    "df_count_df_automl_in_2 = df_count_df_automl_in_2.set_index('Auto ML').T\n",
    "df_count_df_automl_in_2.columns = df_count_df_automl_in_2.columns.str.strip()\n",
    "df_count_df_automl_in_2 = df_count_df_automl_in_2[['Google Cloud AutoML','Azure Automated Machine Learning', 'Amazon Sagemaker Autopilot', 'Databricks AutoML', 'DataRobot AutoML', 'H2O Driverless AI']]\n",
    "\n",
    "# --- Plot ---\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "\n",
    "df_count_df_automl_in_2.plot(kind = 'bar',\n",
    "                ax=ax,\n",
    "                color = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf'])\n",
    "\n",
    "ax.set_title(\"AutoML: Willingness to become more familiar in the next 2 years\", fontsize ='large', pad=20)\n",
    "ax.set_xlabel('Year', fontsize='medium', labelpad=20)\n",
    "ax.set_ylabel('Number of respondents', fontsize='medium', labelpad=20)\n",
    "ax.legend(bbox_to_anchor = (1.8, 0.6), fontsize=20)\n",
    "\n",
    "plt.savefig('5.2 AutoML: Willingness to become more familiar in the next 2 years.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Special hardware usage ---\n",
    "\n",
    "# 2021 Q12 Special hardware usage \n",
    "\n",
    "hardware_2021 = ['Q12_Part_1','Q12_Part_2','Q12_Part_3','Q12_Part_4','Q12_Part_5','Q12_OTHER']\n",
    "hardware_2021_df = pros_2021[hardware_2021]\n",
    "count_hardware_2021 = pd.Series(hardware_2021_df[hardware_2021].squeeze().values.ravel()).value_counts()\n",
    "\n",
    "# 2020 Q12 Special hardware usage \n",
    "\n",
    "hardware_2020 = ['Q12_Part_1','Q12_Part_2','Q12_Part_3','Q12_OTHER']\n",
    "hardware_2020_df = pros_2020[hardware_2020]\n",
    "count_hardware_2020 = pd.Series(hardware_2020_df[hardware_2020].squeeze().values.ravel()).value_counts()\n",
    "\n",
    "# 2021 Q19 Special hardware usage \n",
    "\n",
    "hardware_2019 = ['Q21_Part_1','Q21_Part_2','Q21_Part_3','Q21_Part_4','Q21_Part_5','Q21_OTHER_TEXT']\n",
    "hardware_2019_df = pros_2019[hardware_2019]\n",
    "count_hardware_2019 = pd.Series(hardware_2019_df[hardware_2019].squeeze().values.ravel()).value_counts()\n",
    "\n",
    "df_count_hardware_2021 = pd.DataFrame(count_hardware_2021)\n",
    "df_count_hardware_2021 = df_count_hardware_2021.reset_index()\n",
    "df_count_hardware_2021.columns = ['manage', '2021']\n",
    "\n",
    "df_count_hardware_2020 = pd.DataFrame(count_hardware_2020)\n",
    "df_count_hardware_2020 = df_count_hardware_2020.reset_index()\n",
    "df_count_hardware_2020.columns = ['manage', '2020']\n",
    "\n",
    "df_count_hardware_2019 = pd.DataFrame(count_hardware_2019)\n",
    "df_count_hardware_2019 = df_count_hardware_2019.reset_index()\n",
    "df_count_hardware_2019.columns = ['manage', '2019']\n",
    "\n",
    "df_count_hardware_2019 = df_count_hardware_2019.iloc[1:6]\n",
    "df_count_hardware_2019 = df_count_hardware_2019.set_index('manage').T[['GPUs', 'TPUs','Other']]\n",
    "df_count_hardware_2020 = df_count_hardware_2020.set_index('manage').T[['GPUs', 'TPUs', 'Other']]\n",
    "\n",
    "df_count_hardware_2021 = df_count_hardware_2021.set_index('manage').T\n",
    "df_count_hardware_2021.columns = df_count_hardware_2021.columns.str.strip()\n",
    "df_count_hardware_2021 = df_count_hardware_2021[['NVIDIA GPUs','Google Cloud TPUs','Other','AWS Inferentia Chips','AWS Trainium Chips']]\n",
    "df_count_hardware_2021 = df_count_hardware_2021.rename(columns = {'NVIDIA GPUs': 'GPUs',\n",
    "                                                                    'Google Cloud TPUs': 'TPUs',\n",
    "                                                                    'Other': 'Other',\n",
    "                                                                    'AWS Inferentia Chips': 'AWS Inferentia',\n",
    "                                                                    'AWS Trainium Chips': 'AWS Trainium'})\n",
    "\n",
    "# Merge all three\n",
    "\n",
    "df_hardware_merged = df_count_hardware_2019.append(df_count_hardware_2020).append(df_count_hardware_2021).fillna(0)\n",
    "\n",
    "# --- Plot ---\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "\n",
    "df_hardware_merged.plot(kind = 'bar',\n",
    "                ax=ax,\n",
    "                color = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf'])\n",
    "\n",
    "ax.set_title(\"Special hardware usage trend\", fontsize ='large', pad=20)\n",
    "ax.set_xlabel('Year', fontsize='medium', labelpad=20)\n",
    "ax.set_ylabel('Number of respondents', fontsize='medium', labelpad=20)\n",
    "ax.legend(bbox_to_anchor = (1.5, 0.6), fontsize=20)\n",
    "ax.annotate(\"AWS chips added in 2021\", xy=(2.1, 1000), xytext=(2.3, 1500),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "            )\n",
    "\n",
    "plt.savefig('6.1 Special hardware usage trend.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Special hardware // Company Spending ---\n",
    "\n",
    "# --- Special hardware // Company Spending 2020 Q12 ---\n",
    "\n",
    "large_spender_2020 = pros_2020.loc[pros_2020['Q25'].isin(['$1-$99', '$100-$999', '$1000-$9,999', '$10,000-$99,999', '$100,000 or more ($USD)'])]\n",
    "hardware_2020 = ['Q12_Part_1','Q12_Part_2','Q12_Part_3','Q12_OTHER']\n",
    "\n",
    "spender_hardware_2020 = pd.DataFrame()\n",
    "\n",
    "money_array = ['$1-$99', '$100-$999', '$1000-$9,999', '$10,000-$99,999', '$100,000 or more ($USD)']\n",
    "\n",
    "for idx, comp_size in enumerate(money_array):\n",
    "    spender_comp_size = large_spender_2020.loc[large_spender_2020['Q25'] == comp_size]\n",
    "    idx = pd.Series(spender_comp_size[hardware_2020].squeeze().values.ravel()).value_counts()\n",
    "    spender_hardware_2020[comp_size] = idx\n",
    "    \n",
    "spender_hardware_2020 = spender_hardware_2020.rename(columns = {'$100,000 or more ($USD)': '100,000 +'})\n",
    "spender_hardware_2020 = spender_hardware_2020.T[['GPUs','TPUs', 'Other']]\n",
    "\n",
    "# --- Special hardware // Company Spending 2021 Q26 ---\n",
    "\n",
    "large_spender_2021 = pros_2021.loc[pros_2021['Q26'].isin(['$1-$99', '$100-$999', '$1000-$9,999', '$10,000-$99,999', '$100,000 or more ($USD)'])]\n",
    "\n",
    "hardware_2021 = ['Q12_Part_1','Q12_Part_2','Q12_Part_3','Q12_Part_4','Q12_Part_5','Q12_OTHER']\n",
    "\n",
    "spender_hardware_2021 = pd.DataFrame()\n",
    "\n",
    "money_lst = ['$1-$99', '$100-$999', '$1000-$9,999', '$10,000-$99,999', '$100,000 or more ($USD)']\n",
    "\n",
    "for idx, comp_size in enumerate(money_lst):\n",
    "    spender_comp_size = large_spender_2021.loc[large_spender_2021['Q26'] == comp_size]\n",
    "    idx = pd.Series(spender_comp_size[hardware_2021].squeeze().values.ravel()).value_counts()\n",
    "    spender_hardware_2021[comp_size] = idx\n",
    "    \n",
    "spender_hardware_2021 = spender_hardware_2021.rename(columns = {'$100,000 or more ($USD)': '100,000 +'})\n",
    "spender_hardware_2021 = spender_hardware_2021[1:].T\n",
    "\n",
    "# --- Plot (1) ---\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "\n",
    "spender_hardware_2020.plot(kind = 'bar',\n",
    "                ax=ax,\n",
    "                color = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf'])\n",
    "\n",
    "ax.set_title(\"Special hardware usage by spending size in 2020\", fontsize ='large', pad=20)\n",
    "ax.set_xlabel('Money spent', fontsize='medium', labelpad=20)\n",
    "ax.set_ylabel('Number of respondents', fontsize='medium', labelpad=20)\n",
    "ax.legend(bbox_to_anchor = (1.3, 0.6), fontsize=20)\n",
    "\n",
    "plt.savefig('6.2 Special hardware usage trend.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# --- Plot (2) ---\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "\n",
    "spender_hardware_2021.plot(kind = 'bar',\n",
    "                ax=ax,\n",
    "                color = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf'])\n",
    "\n",
    "ax.set_title(\"Special hardware usage by spending size in 2021\", fontsize ='large', pad=20)\n",
    "ax.set_xlabel('Money spent', fontsize='medium', labelpad=20)\n",
    "ax.set_ylabel('Number of respondents', fontsize='medium', labelpad=20)\n",
    "ax.legend(bbox_to_anchor = (1.6, 0.6), fontsize=20)\n",
    "\n",
    "plt.savefig('6.3 Special hardware usage trend.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- NVIDIA Earnings ---\n",
    "\n",
    "nvda_earnings = pd.read_excel('../input/stonks-data/nvda_earnings.xlsx')\n",
    "nvda_earnings = nvda_earnings.rename(columns = {'Unnamed: 0': 'Revenue'})\n",
    "\n",
    "df = nvda_earnings.T\n",
    "df.columns = df.iloc[0]\n",
    "df = df.drop(df.index[0])\n",
    "df.drop('Total', axis = 1, inplace = True)\n",
    "\n",
    "# --- Plot ---\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 10))\n",
    "\n",
    "df.plot(kind = 'bar',\n",
    "        stacked=True, \n",
    "        ax = ax,\n",
    "       color = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf'])\n",
    "\n",
    "ax.set_title(\"NVIDIA Earnings\", fontsize ='large', pad=20)\n",
    "ax.set_xlabel('Adj Fiscal Year', fontsize='medium', labelpad=20)\n",
    "ax.set_ylabel('in Million USD', fontsize='medium', labelpad=20)\n",
    "ax.legend(bbox_to_anchor = (1.65, 0.6), fontsize=20)\n",
    "\n",
    "plt.annotate('',\n",
    "ha = 'center', va = 'bottom',\n",
    "xytext = (7.8, 1800),\n",
    "xy = (12.3, 3800),\n",
    "arrowprops = { 'facecolor' : 'red', 'shrink' : 0.05 })\n",
    "\n",
    "plt.annotate('Data Center Revenue Explosion Begins',\n",
    "        fontsize = 14,\n",
    "        ha = 'center', va = 'bottom',\n",
    "        xytext = (8, 5000),\n",
    "        xy = (8, 3200),\n",
    "        arrowprops = { 'facecolor' : 'black', 'shrink' : 0.05 })\n",
    "\n",
    "\n",
    "#plt.annotate('Data Center revenue growth 100% YoY in 2020', xytext = (3, 6000), xy = (8, 6000), fontsize = 22, color = 'red', )\n",
    "plt.axhline(y=3200, linestyle='dashed', linewidth=2, color = 'black') \n",
    "plt.annotate('Source: Nvidia', (0,0), (-80,-95), fontsize=8, \n",
    "             xycoords='axes fraction', textcoords='offset points', va='top')\n",
    "\n",
    "plt.rc('font', size=11) \n",
    "for c in (ax.containers):\n",
    "    ax.bar_label(c, label_type='center')\n",
    "    \n",
    "plt.rcParams['font.size'] = 20\n",
    "\n",
    "plt.savefig('7.1 NVIDIA Earnings.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Estimated Public Cloud's Spending on GPU infrastructure ---\n",
    "\n",
    "# Current market share: AWS = 31%, Azure = 22%, and GCP = 8%\n",
    "# Jensen Huang said 51% of data center revenue was coming from public cloud\n",
    "\n",
    "data_center_segment = nvda_earnings.iloc[[2]]\n",
    "data_center_segment = data_center_segment.set_index(['Revenue'])\n",
    "data_center_aws =  data_center_segment.copy() * 0.31\n",
    "data_center_aws = data_center_aws.rename(index = {'data center': 'AWS'})\n",
    "\n",
    "data_center_azure = data_center_segment.copy() * 0.22\n",
    "data_center_azure = data_center_azure.rename(index = {'data center': 'Azure'})\n",
    "\n",
    "data_center_gcp = data_center_segment.copy() * 0.08\n",
    "data_center_gcp = data_center_gcp.rename(index = {'data center': 'GCP'})\n",
    "\n",
    "data_center_others = data_center_segment.copy() * 0.39\n",
    "data_center_others = data_center_others.rename(index = {'data center': 'Other Enterprises'})\n",
    "\n",
    "df_data_center_others = pd.concat([data_center_aws, data_center_azure, data_center_gcp, data_center_others])\n",
    "\n",
    "df_data_center_others.iloc[2, 0] = 0\n",
    "df_data_center_others.iloc[2, 1] = 0\n",
    "df_data_center_others.iloc[2, 2] = 0 \n",
    "df_data_center_others = df_data_center_others.T\n",
    "df_data_center_others = df_data_center_others[['AWS', 'Azure', 'GCP']]*0.51\n",
    "\n",
    "# --- Plot ---\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10, 10))\n",
    "\n",
    "df_data_center_others.plot(kind = 'bar',\n",
    "        ax = ax,\n",
    "       color = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf'])\n",
    "\n",
    "ax.set_title(\"Estimated Nvidia's revenue from the big 3\", fontsize ='large', pad=20)\n",
    "ax.set_xlabel('Adj Fiscal Year', fontsize='medium', labelpad=20)\n",
    "ax.set_ylabel('in Million USD', fontsize='medium', labelpad=20)\n",
    "ax.legend(bbox_to_anchor = (1.3, 0.6), fontsize=20)\n",
    "\n",
    "plt.axvline(x=2.5, linestyle='dashed', linewidth=2, color = 'black') \n",
    "plt.annotate('Google disclosed GCP as of 2019', xytext = (2.6, 600), xy = (8, 600), fontsize = 14, color = 'black')\n",
    "\n",
    "plt.annotate('Source: NVIDIA, https://www.parkmycloud.com/', (0,0), (-80,-120), fontsize=8, \n",
    "             xycoords='axes fraction', textcoords='offset points', va='top')\n",
    "\n",
    "plt.savefig(\"7.2 Estimated Nvidia's revenue from the big 3.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvda_stocks = pd.read_excel('../input/nvda-market-cap/nvda_marketcap.xlsx')\n",
    "nvda_stocks = nvda_stocks.head(1000)\n",
    "nvda_stocks = nvda_stocks.rename(columns = {'NVDA.O (Fundamental)': 'Market Cap'})\n",
    "nvda_stocks = nvda_stocks.iloc[1:, :]\n",
    "nvda_stocks = nvda_stocks.drop('NVDA.O', axis = 1)\n",
    "nvda_stocks = nvda_stocks.set_index('Date')\n",
    "nvda_stocks = nvda_stocks.div(1000000000)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18,6))\n",
    "nvda_stocks.plot(ax=ax,\n",
    "                    color = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf'])\n",
    "\n",
    "ax.set_title(\"NVDA Market cap\", fontsize ='large', pad=20)\n",
    "ax.set_xlabel('Date', fontsize='medium', labelpad=20)\n",
    "ax.set_ylabel('Market cap (Billions)', fontsize='medium', labelpad=20)\n",
    "ax.legend(bbox_to_anchor = (1.2, 0.6), fontsize=20)\n",
    "\n",
    "plt.annotate('Gaming, Crypto and Cloud Beneficiary', (0,0), (500,150), fontsize=15, \n",
    "             xycoords='axes fraction', textcoords='offset points', va='top')\n",
    "\n",
    "plt.annotate('Accelerated AI competition', (0,0), (800,220), fontsize=15, \n",
    "             xycoords='axes fraction', textcoords='offset points', va='top')\n",
    "\n",
    "plt.annotate('META', (0,0), (950,280), fontsize=15, \n",
    "             xycoords='axes fraction', textcoords='offset points', va='top')\n",
    "\n",
    "plt.annotate('Source: Refinitiv', (0,0), (-80,-80), fontsize=8, \n",
    "             xycoords='axes fraction', textcoords='offset points', va='top')\n",
    "\n",
    "plt.savefig(\"NVDIA_market_cap.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Science professional distribution ---\n",
    "\n",
    "# Get data from 2021\n",
    "\n",
    "industry_2021 = data_2021[data_2021['Q20'].notna()]\n",
    "c = industry_2021['Q20'].value_counts(normalize=True).rename_axis('industry').reset_index(name='counts')\n",
    "#c =industry_2021['Q20'].value_counts().rename_axis('industry').reset_index(name='counts')\n",
    "\n",
    "# Get data from 2018\n",
    "\n",
    "industry_2018 = data_2018[data_2018['Q7'] != 'I am a student']\n",
    "industry_2018 = industry_2018[industry_2018['Q7'].notna()]\n",
    "d = industry_2018['Q7'].value_counts(normalize=True).rename_axis('industry').reset_index(name='counts')\n",
    "#d = industry_2018['Q7'].value_counts().rename_axis('industry').reset_index(name='counts')\n",
    "\n",
    "# compute the industry\n",
    "\n",
    "k = pd.merge(left = d, right = c, on = 'industry')\n",
    "k = k.rename(columns = {'counts_x': '2018', 'counts_y': '2021'})\n",
    "k = k.sort_values(by=['2021'], ascending=False)\n",
    "\n",
    "# compute the difference\n",
    "diff_industry = k.copy()\n",
    "diff_industry['dff'] = k['2021'] - k['2018']\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize = (20,10))\n",
    "\n",
    "gs = gridspec.GridSpec(1, 2, wspace=0.2,hspace=0.5, width_ratios=[3,1]) \n",
    "\n",
    "ax1 = plt.subplot(gs[0])\n",
    "k.plot.barh(x = \"industry\", \n",
    "            ax= ax1,\n",
    "           color = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf'])\n",
    "ax1.set(title = \"Data Science professionals distribution by Industry. 2018 vs 2021\",\n",
    "      xlabel = \"Percentage (Total sum = 1.0)\",\n",
    "      ylabel = \"Industry\")\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "ax2 = plt.subplot(gs[1])\n",
    "diff_industry['dff'].plot(kind='barh', x = 'industry', ax = ax2,\n",
    "                    color=(diff_industry['dff'] > 0).map({True: 'g',\n",
    "                                                    False: 'r'}))\n",
    "ax2.set(title = \"Change\",\n",
    "      xlabel = \"Percentage\",\n",
    "      ylabel = \"Industry\")\n",
    "plt.xticks(rotation=45)\n",
    "ax2.set_yticks([])\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.savefig(\"8.1 Data Science professionals distribution by Industry. 2018 vs 2021.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exhibit 1.1 Data Science distribution by company size 2021.\n",
    "\n",
    "test = get_professionals(data_2021, 'Q5')\n",
    "#print(len(test))\n",
    "test = test[test['Q21'].notna()]\n",
    "#print(len(test))\n",
    "\n",
    "category_test = test.groupby(['Q20', 'Q21']).size()\n",
    "#category_test.plot(kind='bar')\n",
    "new_df = category_test.to_frame(name = 'size').reset_index()\n",
    "new_df_2= pd.pivot(\n",
    "    data = new_df,\n",
    "    index = 'Q20',\n",
    "    columns = 'Q21',\n",
    "    values = 'size',\n",
    ")\n",
    "new_df_2.index.names = ['Industry']\n",
    "new_df_2.columns.names = ['Company Size']\n",
    "\n",
    "columns_order = ['0-49 employees', '50-249 employees', '250-999 employees', '1000-9,999 employees','10,000 or more employees']\n",
    "\n",
    "new_df_2 = new_df_2.reindex(columns = columns_order)\n",
    "new_df_2['total'] = new_df_2[columns_order].sum(axis = 1)\n",
    "new_df_2 = new_df_2.sort_values(by = 'total', ascending = False)\n",
    "new_df_2 = new_df_2.drop(columns='total')\n",
    "\n",
    "# -----\n",
    "\n",
    "\n",
    "new_df_2['total'] = new_df_2[columns_order].sum(axis = 1)\n",
    "new_df_2 = new_df_2.sort_values(by = 'total', ascending = False)\n",
    "new_df_2 = new_df_2.drop(columns = 'total')\n",
    "res = new_df_2.div(new_df_2.sum(axis=1), axis = 0)\n",
    "\n",
    "# --------------------- plot ---------------------\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize = (20,10))\n",
    "\n",
    "gs = gridspec.GridSpec(1, 2, wspace=0.2,hspace=0.5, width_ratios=[3,1]) \n",
    "\n",
    "ax1 = plt.subplot(gs[0])\n",
    "new_df_2.plot(use_index = True,  \n",
    "              kind='barh', \n",
    "              stacked=True, \n",
    "              ax = ax1,\n",
    "              color = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "              )\n",
    "\n",
    "ax1.set(title = \"DS professional distibution by company size across different industry 2021\",\n",
    "      xlabel = \"the number of respondents\",\n",
    "      ylabel = \"Industry\")\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "ax2 = plt.subplot(gs[1])\n",
    "res.plot(use_index = True,  \n",
    "              kind='barh', \n",
    "              stacked=True, \n",
    "              ax = ax2,\n",
    "         color = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "              )\n",
    "ax2.set(title='Company Size portion',\n",
    "      xlabel = \"Percentage\",\n",
    "      ylabel = \" \")\n",
    "\n",
    "#plt.legend(title = \"Company Size\", bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
    "ax2.get_legend().remove()\n",
    "ax2.set_yticks([])\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.savefig(\"8.2 DS professional distibution by company size across different industry 2021.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Industry and professionals heatmap\n",
    "\n",
    "# ----------------\n",
    "# Job title filter\n",
    "# ----------------\n",
    "\n",
    "job_title = {'Other':'Other',\n",
    "     'Product Manager': 'Product/Project Manager',\n",
    " 'Program/Project Manager':'Product/Project Manager',\n",
    " 'Principal Investigator':'Product/Project Manager',\n",
    " 'Chief Officer':'Product/Project Manager',\n",
    " 'Manager':'Product/Project Manager',\n",
    " 'Software Developer/Software Engineer': 'Software Engineer',\n",
    " 'Operations Research Practitioner': 'Research Scientist',\n",
    " 'Computer Scientist': 'Research Scientist',\n",
    " 'Scientist/Researcher': 'Research Scientist',\n",
    " 'Researcher': 'Research Scientist',\n",
    " 'Data Scientist': 'Data Scientist',\n",
    "     'Business Analyst': 'Business Analyst',\n",
    "     'Engineer': 'Other',\n",
    "     'DBA/Database Engineer': 'DBA/Database Engineer',\n",
    "     'Data Analyst':'Data Analyst',\n",
    "     'Machine Learning Engineer': 'Machine Learning Engineer',\n",
    "     'Statistician':'Statistician',\n",
    "     'Predictive Modeler':'Research Scientist',\n",
    "     'Programmer': 'Software Engineer',\n",
    "     'Data Miner': 'Data Engineer',\n",
    "     'Consultant': 'Other',\n",
    "     'Research Assistant': 'Research Scientist',\n",
    "     'Chief Officer':'Product/Project Manager',\n",
    "     'Data Engineer':'Data Engineer',\n",
    "     'Developer Advocate': 'Developer Relations/Advocacy',\n",
    "     'Marketing Analyst': 'Business Analyst',\n",
    "     'Data Analyst': 'Data Analyst',\n",
    "     'Software Engineer': 'Software Engineer',\n",
    "     'Research Scientist': 'Research Scientist',\n",
    "     'Data Journalist': 'Data Analyst',\n",
    "     'Salesperson':'Developer Relations/Advocacy',\n",
    "     'Product/Project Manager': 'Product/Project Manager',\n",
    "     'Developer Relations/Advocacy': 'Developer Relations/Advocacy'\n",
    "}\n",
    "\n",
    "# -----------------------------------------\n",
    "# Heatmap of job title within industry 2021\n",
    "# -----------------------------------------\n",
    "\n",
    "workforce_2021 = get_professionals(data_2021, 'Q5')\n",
    "professional_2021 = workforce_2021[workforce_2021['Q20'].notna()]\n",
    "professional_2021['Q5'] = professional_2021['Q5'].map(job_title)\n",
    "industry_2021 = professional_2021['Q20'].unique()\n",
    "df_2021 = professional_2021[['Q5','Q20']]\n",
    "\n",
    "temp_d = {}\n",
    "\n",
    "for industry in industry_2021:\n",
    "    temp_df = df_2021[df_2021['Q20'] == industry]\n",
    "    temp_dict = dict(temp_df['Q5'].value_counts())\n",
    "    temp_d[industry] = temp_dict\n",
    "\n",
    "def sorted_simple_dict(d):\n",
    "    return {k: v for k, v in sorted(d.items())}\n",
    "\n",
    "def sorted_once_nested_dict(d):\n",
    "    return {k: sorted_simple_dict(v) for k, v in sorted(d.items())}\n",
    "\n",
    "temp_d = sorted_once_nested_dict(temp_d)\n",
    "\n",
    "d_2021 = {}\n",
    "\n",
    "h_lst = list(k['industry'])\n",
    "\n",
    "for i in h_lst:\n",
    "    d_2021[i] = temp_d[i]\n",
    "\n",
    "df_industry_2021 = pd.DataFrame.from_dict(d_2021, orient='index')\n",
    "df_industry_2021.fillna(0, inplace = True)\n",
    "df_industry_2021 = df_industry_2021.sort_values(by=df_industry_2021.index[0], ascending=False, axis=1)\n",
    "df_industry_2021\n",
    "\n",
    "# -----------------------------------------\n",
    "# Heatmap of job title within industry 2021\n",
    "# -----------------------------------------\n",
    "\n",
    "student_2018 = data_2018.loc[data_2018['Q7'] == 'I am a student']\n",
    "workforce_2018 = data_2018.loc[data_2018['Q7'] != 'I am a student']\n",
    "\n",
    "professional_2018 = workforce_2018[workforce_2018['Q7'].notna()]\n",
    "professional_2018['Q6'] = professional_2018['Q6'].map(job_title)\n",
    "\n",
    "industry_2018 = professional_2018['Q7'].unique()\n",
    "\n",
    "df_2018 = professional_2018[['Q6','Q7']]\n",
    "\n",
    "temp_d = {}\n",
    "\n",
    "for industry in industry_2018:\n",
    "    temp_df = df_2018[df_2018['Q7'] == industry]\n",
    "    temp_dict = dict(temp_df['Q6'].value_counts())\n",
    "    temp_d[industry] = temp_dict\n",
    "\n",
    "def sorted_simple_dict(d):\n",
    "    return {k: v for k, v in sorted(d.items())}\n",
    "\n",
    "def sorted_once_nested_dict(d):\n",
    "    return {k: sorted_simple_dict(v) for k, v in sorted(d.items())}\n",
    "\n",
    "temp_d = sorted_once_nested_dict(temp_d)\n",
    "\n",
    "d_2018 = {}\n",
    "\n",
    "for i in h_lst:\n",
    "    d_2018[i] = temp_d[i]\n",
    "\n",
    "df_industry_2018 = pd.DataFrame.from_dict(d_2018, orient='index')\n",
    "df_industry_2018.fillna(0, inplace = True)\n",
    "df_industry_2018 = df_industry_2018.sort_values(by=df_industry_2018.index[0], ascending=False, axis=1)\n",
    "\n",
    "# --- Plot ---\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(ncols = 2, figsize=(20,10))\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "plt.title('2018 industry workforce distribution heatmap')\n",
    "sns.heatmap(df_industry_2018, annot=True, annot_kws = {\"size\": 8}, linewidth = 0.5, fmt='g', square=True, cmap = 'BuGn')\n",
    "\n",
    "fig.subplots_adjust(wspace=0.2)\n",
    "\n",
    "ax2 = plt.subplot(122)\n",
    "plt.title('2021 industry workforce distribution heatmap')\n",
    "sns.heatmap(df_industry_2021, annot=True, annot_kws = {\"size\": 8}, linewidth = 0.5, fmt='g', square=True, cmap = 'BuGn')\n",
    "\n",
    "plt.axvline(x = 2, ymin= -0.05, ymax= 1.1, color='red', linestyle='solid', linewidth=5)\n",
    "plt.axvline(x = 3, ymin= -0.05, ymax= 1.1, color='red', linestyle='solid', linewidth=5)\n",
    "\n",
    "frame1 = plt.gca()\n",
    "frame1.axes.yaxis.set_ticklabels([])\n",
    "\n",
    "plt.savefig(\"9.1 industry workforce heatmap.png\", bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Job title and Tasks during the work ---\n",
    "\n",
    "from math import pi\n",
    "# activities at work\n",
    "\n",
    "# Q24_Part_1\tQ24_Part_2\tQ24_Part_3\tQ24_Part_4\tQ24_Part_5\tQ24_Part_6\tQ24_Part_7\tQ24_OTHER\n",
    "\n",
    "activities_2021 = ['Q24_Part_1','Q24_Part_2','Q24_Part_3','Q24_Part_4','Q24_Part_5','Q24_Part_6','Q24_Part_7','Q24_OTHER']\n",
    "\n",
    "role_2021 = ['Q5']\n",
    "\n",
    "role_activities_2021 = ['Q5','Q24_Part_1','Q24_Part_2','Q24_Part_3','Q24_Part_4','Q24_Part_5','Q24_Part_6','Q24_Part_7','Q24_OTHER']\n",
    "\n",
    "job_name = ['Data Scientist', 'Machine Learning Engineer',  'Software Engineer', 'Data Analyst', 'Research Scientist']\n",
    "\n",
    "df_role_act_2021 = pros_2021[role_activities_2021]\n",
    "\n",
    "df_role_act_2021 = df_role_act_2021[df_role_act_2021['Q5'].isin(job_name)]\n",
    "\n",
    "df_role_act_2021[activities_2021] = df_role_act_2021[activities_2021].notnull().astype('int')\n",
    "\n",
    "# --------------\n",
    "\n",
    "df_SE = df_role_act_2021[df_role_act_2021['Q5'] == 'Software Engineer']\n",
    "df_SE = df_SE.groupby(by='Q5', dropna=False).sum()\n",
    "df_SE = df_SE.rename(columns = {'Q24_Part_1': 'Analyze data', \n",
    "                     'Q24_Part_2': 'Build infrastructure', \n",
    "                     'Q24_Part_3': 'Build ML prototypes', \n",
    "                     'Q24_Part_4': 'Deploy & Improve',\n",
    "                     'Q24_Part_5': 'Improve existing ML',\n",
    "                     'Q24_Part_6': 'Do research',\n",
    "                     'Q24_Part_7': 'None',\n",
    "                     'Q24_OTHER': 'Other'\n",
    "                    })\n",
    "\n",
    "df_SE = df_SE.T.reset_index()\n",
    "\n",
    "# --------------\n",
    "\n",
    "df_DS = df_role_act_2021[df_role_act_2021['Q5'] == 'Data Scientist']\n",
    "df_DS = df_DS.groupby(by='Q5', dropna=False).sum()\n",
    "df_DS = df_DS.rename(columns = {'Q24_Part_1': 'Analyze data', \n",
    "                     'Q24_Part_2': 'Build infrastructure', \n",
    "                     'Q24_Part_3': 'Build ML prototypes', \n",
    "                     'Q24_Part_4': 'Deploy & Improve',\n",
    "                     'Q24_Part_5': 'Improve existing ML',\n",
    "                     'Q24_Part_6': 'Do research',\n",
    "                     'Q24_Part_7': 'None',\n",
    "                     'Q24_OTHER': 'Other'\n",
    "                    })\n",
    "df_DS = df_DS.T.reset_index()\n",
    "\n",
    "# -------------\n",
    "\n",
    "df_MLE = df_role_act_2021[df_role_act_2021['Q5'] == 'Machine Learning Engineer']\n",
    "\n",
    "df_MLE = df_MLE.groupby(by='Q5', dropna=False).sum()\n",
    "df_MLE = df_MLE.rename(columns = {'Q24_Part_1': 'Analyze data', \n",
    "                     'Q24_Part_2': 'Build infrastructure', \n",
    "                     'Q24_Part_3': 'Build ML prototypes', \n",
    "                     'Q24_Part_4': 'Deploy & Improve',\n",
    "                     'Q24_Part_5': 'Improve existing ML',\n",
    "                     'Q24_Part_6': 'Do research',\n",
    "                     'Q24_Part_7': 'None',\n",
    "                     'Q24_OTHER': 'Other'\n",
    "                    })\n",
    "df_MLE = df_MLE.T.reset_index()\n",
    "\n",
    "#----------\n",
    "\n",
    "df_MLE['percent'] = (df_MLE['Machine Learning Engineer'] / \n",
    "                  df_MLE['Machine Learning Engineer'].sum()) * 100\n",
    "df_MLE = df_MLE.drop('Machine Learning Engineer', axis = 1)\n",
    "\n",
    "df_DS['percent'] = (df_DS['Data Scientist'] / \n",
    "                  df_DS['Data Scientist'].sum()) * 100\n",
    "df_DS = df_DS.drop('Data Scientist', axis = 1)\n",
    "\n",
    "df_SE['percent'] = (df_SE['Software Engineer'] / \n",
    "                  df_SE['Software Engineer'].sum()) * 100\n",
    "df_SE = df_SE.drop('Software Engineer', axis = 1)\n",
    "\n",
    "# -------\n",
    "\n",
    "theta = np.arange(len(df_MLE) + 1) / float(len(df_MLE)) * 2 * np.pi\n",
    "values = df_MLE['percent'].values\n",
    "values = np.append(values, values[0])\n",
    "\n",
    "values1 = df_DS['percent'].values\n",
    "values1 = np.append(values1, values1[0])\n",
    "\n",
    "values2 = df_SE['percent'].values\n",
    "values2 = np.append(values2, values2[0])\n",
    "\n",
    "# --- Plot ---\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.suptitle(\"Tasks in workplace. MLE vs. DS vs. SE\", y = 1)\n",
    "\n",
    "ax = plt.subplot(projection=\"polar\")\n",
    "\n",
    "# draw the polygon and the mark the points for each angle/value combination\n",
    "l1, = ax.plot(theta, values, color=\"C2\", marker=\"o\", label=\"MLE\")\n",
    "l2, = ax.plot(theta, values1, color=\"C3\", marker=\"o\", label=\"DS\")\n",
    "l3, = ax.plot(theta, values2, color=\"C4\", marker=\"o\", label=\"SE\")\n",
    "\n",
    "plt.xticks(theta[:-1], df_MLE['index'], color='grey', size=20)\n",
    "ax.tick_params(pad=40) # to increase the distance of the labels to the plot\n",
    "# fill the area of the polygon with green and some transparency\n",
    "ax.fill(theta, values, 'green', alpha=0.1)\n",
    "ax.fill(theta, values1, 'red', alpha=0.1)\n",
    "ax.fill(theta, values2, 'purple', alpha=0.1)\n",
    "ax.legend(loc = 'lower right',bbox_to_anchor = (1.3,0.1))\n",
    "\n",
    "plt.savefig(\"9.2 Tasks in workplace. MLE vs. DS vs. SE.png\", bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_professionals(data_2021, 'Q5')\n",
    "\n",
    "# ----------------------------------------------------------------------------------------\n",
    "# 2021 (#18 and #19), 2020 (#18 and #19), 2019 (#26 and #27) About Computer vision and NLP\n",
    "# ----------------------------------------------------------------------------------------\n",
    "\n",
    "# ---------------------------------\n",
    "# COMPUTER VISION YES OR NO in 2021\n",
    "# ---------------------------------\n",
    "\n",
    "vision = test[['Q18_Part_1','Q18_Part_2','Q18_Part_3','Q18_Part_4','Q18_Part_5','Q18_Part_6','Q18_OTHER']]\n",
    "nlp = test[['Q19_Part_1','Q19_Part_2','Q19_Part_3','Q19_Part_4','Q19_Part_5','Q19_OTHER']]\n",
    "vision = vision.fillna(0)\n",
    "vision[vision != 0] = 1\n",
    "vision_df = vision[vision==True].count(axis=0).rename_axis('Algo').reset_index(name='counts')\n",
    "vision_df = vision_df.set_index('Algo').T\n",
    "stuff_2020 = vision_df\n",
    "\n",
    "vision['yes'] = vision[['Q18_Part_1','Q18_Part_2','Q18_Part_3','Q18_Part_4','Q18_Part_5','Q18_OTHER']].sum(axis = 1)\n",
    "vision['yes'] = vision['yes'].apply(lambda x: x>=1)\n",
    "#vision['yes'].value_counts()\n",
    "vision['no'] = (vision['yes'].apply(lambda x: x == 0) | vision['Q18_Part_6'].apply(lambda x: x == 1))\n",
    "#vision['no'].value_counts()\n",
    "\n",
    "vision['Q20'] = test['Q20']\n",
    "vision = vision.drop(columns=['Q18_Part_1','Q18_Part_2','Q18_Part_3','Q18_Part_4','Q18_Part_5','Q18_Part_6','Q18_OTHER'])\n",
    "vision.replace({False: 0, True: 1}, inplace=True)\n",
    "vision_df = vision[vision['yes'] == 1].groupby('Q20').size()\n",
    "\n",
    "total_boss = vision['Q20'].value_counts()\n",
    "\n",
    "boss = pd.DataFrame(vision_df)\n",
    "total_boss = pd.DataFrame(total_boss)\n",
    "final_boss = total_boss.join(boss)\n",
    "final_boss.rename(columns = {final_boss.columns[0]: 'NO', final_boss.columns[1]: 'YES'}, inplace = True)\n",
    "final_boss = final_boss[::-1]\n",
    "\n",
    "# --- Plot ---\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "final_boss.plot(kind='barh',\n",
    "                ax = ax,\n",
    "                color = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf'])\n",
    "ax.set(title = \"Computer Vision Yes / No\",\n",
    "       xlabel = \"the number of respondents\",\n",
    "       ylabel = \"Industry\")\n",
    "\n",
    "plt.rc('font', size=12)\n",
    "\n",
    "for i,j in (zip(ax.containers[0], ax.containers[1])):\n",
    "\n",
    "    perc = j.get_width() / i.get_width()\n",
    "    perc = (perc*100).round(1)\n",
    "    non_perc = (100 - perc).round(1)\n",
    "    \n",
    "    width = i.get_width()\n",
    "    height = i.get_height()\n",
    "    x, y = i.get_xy()\n",
    "    ax.annotate(f'{non_perc}%', (x + width, y + height*1.02), ha=\"left\", va=\"center\")\n",
    "    \n",
    "    width2 = j.get_width()\n",
    "    height2 = j.get_height()\n",
    "    x2, y2 = j.get_xy() \n",
    "    ax.annotate(f'{perc}%', (x + width2, y2 + height2*1.02), ha=\"left\", va=\"center\")\n",
    "    \n",
    "plt.rcParams['font.size'] = 20\n",
    "\n",
    "plt.savefig(\"10.1 Computer Vision.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# NLP YES OR NO in 2021\n",
    "# ---------------------\n",
    "\n",
    "nlp = test[['Q19_Part_1','Q19_Part_2','Q19_Part_3','Q19_Part_4','Q19_Part_5','Q19_OTHER']]\n",
    "nlp = nlp.fillna(0)\n",
    "nlp[nlp != 0] = 1\n",
    "nlp_df = nlp[nlp==True].count(axis=0).rename_axis('Algo').reset_index(name='counts')\n",
    "nlp_df = nlp_df.set_index('Algo').T\n",
    "\n",
    "nlp['yes'] = nlp[['Q19_Part_1','Q19_Part_2','Q19_Part_3','Q19_Part_4','Q19_OTHER']].sum(axis = 1)\n",
    "nlp['yes'] = nlp['yes'].apply(lambda x: x>=1)\n",
    "#vision['yes'].value_counts()\n",
    "nlp['no'] = (nlp['yes'].apply(lambda x: x == 0) | nlp['Q19_Part_5'].apply(lambda x: x == 1))\n",
    "#vision['no'].value_counts()\n",
    "\n",
    "nlp['Q20'] = test['Q20']\n",
    "nlp = nlp.drop(columns=['Q19_Part_1','Q19_Part_2','Q19_Part_3','Q19_Part_4','Q19_Part_5','Q19_OTHER'])\n",
    "nlp.replace({False: 0, True: 1}, inplace=True)\n",
    "nlp_df = nlp[nlp['yes'] == 1].groupby('Q20').size()\n",
    "\n",
    "total_boss2 = nlp['Q20'].value_counts()\n",
    "\n",
    "boss2 = pd.DataFrame(nlp_df)\n",
    "total_boss2 = pd.DataFrame(total_boss2)\n",
    "final_boss2 = total_boss.join(boss2)\n",
    "final_boss2.rename(columns = {final_boss2.columns[1]: 'hello'}, inplace = True)\n",
    "#final_boss2['perc'] = final_boss2['hello'] * 100 / final_boss2['Q20']\n",
    "final_boss2.rename(columns = {final_boss2.columns[0]: 'NO', final_boss2.columns[1]: 'YES'}, inplace = True)\n",
    "final_boss2 = final_boss2[::-1]\n",
    "\n",
    "# --------------- \n",
    "#  SUBPLOTS - 1x3\n",
    "# ---------------\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "final_boss2.plot(kind='barh',\n",
    "                 ax = ax,\n",
    "                color = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf'])\n",
    "ax.set(title = \"NLP Yes / No\",\n",
    "       xlabel = \"the number of respondents\",\n",
    "       ylabel = \"Industry\")\n",
    "\n",
    "plt.rc('font', size=12)\n",
    "\n",
    "for i,j in (zip(ax.containers[0], ax.containers[1])):\n",
    "\n",
    "    perc = j.get_width() / i.get_width()\n",
    "    perc = (perc*100).round(1)\n",
    "    non_perc = (100 - perc).round(2)\n",
    "    \n",
    "    width = i.get_width()\n",
    "    height = i.get_height()\n",
    "    x, y = i.get_xy()\n",
    "    ax.annotate(f'{non_perc}%', (x + width, y + height*1.02), ha=\"left\", va=\"center\")\n",
    "    \n",
    "    width2 = j.get_width()\n",
    "    height2 = j.get_height()\n",
    "    x2, y2 = j.get_xy() \n",
    "    ax.annotate(f'{perc}%', (x + width2, y2 + height2*1.02), ha=\"left\", va=\"center\")\n",
    "\n",
    "plt.rcParams['font.size'] = 20\n",
    "\n",
    "plt.savefig(\"10.2 NLP.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_framework_2021 = ['Q16_Part_1',\n",
    "                     'Q16_Part_2',\n",
    "                     'Q16_Part_3',\n",
    "                     'Q16_Part_4',\n",
    "                     'Q16_Part_5',\n",
    "                     'Q16_Part_6',\n",
    "                     'Q16_Part_7',\n",
    "                     'Q16_Part_8',\n",
    "                     'Q16_Part_9',\n",
    "                     'Q16_Part_10',\n",
    "                     'Q16_Part_11',\n",
    "                     'Q16_Part_12',\n",
    "                     'Q16_Part_13',\n",
    "                     'Q16_Part_14',\n",
    "                     'Q16_Part_15',\n",
    "                     'Q16_Part_16',\n",
    "                     'Q16_Part_17'\n",
    "                     ,'Q16_OTHER']\n",
    "\n",
    "df_ML_framework_2021 = pros_2021[ML_framework_2021]\n",
    "count_ML_framework_2021 = pd.Series(df_ML_framework_2021[ML_framework_2021].squeeze().values.ravel()).value_counts()\n",
    "\n",
    "df_count_ML_framework_2021 = pd.DataFrame(count_ML_framework_2021)\n",
    "df_count_ML_framework_2021 = df_count_ML_framework_2021.reset_index()\n",
    "df_count_ML_framework_2021.columns = ['ML Frameworks', 'Counts']\n",
    "\n",
    "df_count_ML_framework_2021 = df_count_ML_framework_2021.set_index('ML Frameworks').T\n",
    "df_count_ML_framework_2021.columns = df_count_ML_framework_2021.columns.str.strip()\n",
    "\n",
    "ML_framework_2020 = ['Q16_Part_1',\n",
    "                     'Q16_Part_2',\n",
    "                     'Q16_Part_3',\n",
    "                     'Q16_Part_4',\n",
    "                     'Q16_Part_5',\n",
    "                     'Q16_Part_6',\n",
    "                     'Q16_Part_7',\n",
    "                     'Q16_Part_8',\n",
    "                     'Q16_Part_9',\n",
    "                     'Q16_Part_10',\n",
    "                     'Q16_Part_11',\n",
    "                     'Q16_Part_12',\n",
    "                     'Q16_Part_13',\n",
    "                     'Q16_Part_14',\n",
    "                     'Q16_Part_15',\n",
    "                     'Q16_OTHER']\n",
    "\n",
    "df_ML_framework_2020 = pros_2020[ML_framework_2020]\n",
    "count_ML_framework_2020 = pd.Series(df_ML_framework_2020[ML_framework_2020].squeeze().values.ravel()).value_counts()\n",
    "\n",
    "df_count_ML_framework_2020 = pd.DataFrame(count_ML_framework_2020)\n",
    "df_count_ML_framework_2020 = df_count_ML_framework_2020.reset_index()\n",
    "df_count_ML_framework_2020.columns = ['ML Frameworks', 'Counts']\n",
    "\n",
    "df_count_ML_framework_2020 = df_count_ML_framework_2020.set_index('ML Frameworks').T\n",
    "df_count_ML_framework_2020.columns = df_count_ML_framework_2020.columns.str.strip()\n",
    "\n",
    "ML_framework_2019 = ['Q28_Part_1',\n",
    "                     'Q28_Part_2',\n",
    "                     'Q28_Part_3',\n",
    "                     'Q28_Part_4',\n",
    "                     'Q28_Part_5',\n",
    "                     'Q28_Part_6',\n",
    "                     'Q28_Part_7',\n",
    "                     'Q28_Part_8',\n",
    "                     'Q28_Part_9',\n",
    "                     'Q28_Part_10',\n",
    "                     'Q28_Part_11',\n",
    "                     'Q28_Part_12',\n",
    "                     'Q28_OTHER_TEXT']\n",
    "\n",
    "df_ML_framework_2019 = pros_2019[ML_framework_2019]\n",
    "count_ML_framework_2019 = pd.Series(df_ML_framework_2019[ML_framework_2019].squeeze().values.ravel()).value_counts()\n",
    "\n",
    "df_count_ML_framework_2019 = pd.DataFrame(count_ML_framework_2019)\n",
    "df_count_ML_framework_2019 = df_count_ML_framework_2019.reset_index()\n",
    "df_count_ML_framework_2019.columns = ['ML Frameworks', 'Counts']\n",
    "\n",
    "# Some clean up\n",
    "df_count_ML_framework_2019 = df_count_ML_framework_2019.set_index('ML Frameworks').T\n",
    "df_count_ML_framework_2019.columns = df_count_ML_framework_2019.columns.str.strip()\n",
    "df_count_ML_framework_2019 = df_count_ML_framework_2019[['Scikit-learn', 'Keras', 'TensorFlow', 'RandomForest', 'Xgboost', 'PyTorch', 'LightGBM', 'None', 'Caret', 'Spark MLib',\n",
    "                           'Fast.ai', 'Other']]\n",
    "\n",
    "merged_ML_framcework = pd.concat([df_count_ML_framework_2019, df_count_ML_framework_2020, df_count_ML_framework_2021])\n",
    "merged_ML_framcework.index = ['2019','2020','2021']\n",
    "merged_ML_framcework = merged_ML_framcework.fillna(0)\n",
    "merged_ML_framcework['total'] = merged_ML_framcework.sum(axis=1)\n",
    "merged_ML_framcework[['TensorFlow', 'PyTorch', 'Keras', 'total']]\n",
    "\n",
    "merged_ML_framcework['TensorFlow'] = merged_ML_framcework['TensorFlow']/merged_ML_framcework['total']\n",
    "merged_ML_framcework['PyTorch'] = merged_ML_framcework['PyTorch']/merged_ML_framcework['total']\n",
    "merged_ML_framcework['Keras'] = merged_ML_framcework['Keras']/merged_ML_framcework['total']\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "\n",
    "merged_ML_framcework[['TensorFlow', 'PyTorch','Keras']].plot(kind='bar',\n",
    "                                                     ax=ax,\n",
    "                                                     stacked = True,\n",
    "                                                     color = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf'])\n",
    "\n",
    "ax.set_title(\"ML frameworks usage proportion\", fontsize ='large', pad=20)\n",
    "ax.set_xlabel('Year', fontsize='medium', labelpad=20)\n",
    "ax.set_ylabel('Percentage', fontsize='medium', labelpad=20)\n",
    "ax.legend(bbox_to_anchor = (1.4, 0.6), fontsize=20)\n",
    "\n",
    "plt.savefig(\"11.1 Softpower ML frameworks.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosting_notebook_2021 = ['Q10_Part_1',\n",
    "                    'Q10_Part_2',\n",
    "                    'Q10_Part_3',\n",
    "                    'Q10_Part_4',\n",
    "                    'Q10_Part_5',\n",
    "                    'Q10_Part_6',\n",
    "                    'Q10_Part_7',\n",
    "                    'Q10_Part_8',\n",
    "                    'Q10_Part_9',\n",
    "                    'Q10_Part_10',\n",
    "                    'Q10_Part_11',\n",
    "                    'Q10_Part_12',\n",
    "                    'Q10_Part_13',\n",
    "                    'Q10_Part_14',\n",
    "                    'Q10_Part_15',\n",
    "                    'Q10_Part_16',\n",
    "                    'Q10_OTHER'\n",
    "                   ]\n",
    "\n",
    "df_hosting_notebook_2021 = pros_2021[hosting_notebook_2021]\n",
    "count_hosting_notebook_2021 = pd.Series(df_hosting_notebook_2021[hosting_notebook_2021].squeeze().values.ravel()).value_counts()\n",
    "\n",
    "df_count_hosting_notebook_2021 = pd.DataFrame(count_hosting_notebook_2021)\n",
    "df_count_hosting_notebook_2021 = df_count_hosting_notebook_2021.reset_index()\n",
    "df_count_hosting_notebook_2021.columns = ['ML Frameworks', 'Counts']\n",
    "\n",
    "df_count_hosting_notebook_2021 = df_count_hosting_notebook_2021.set_index('ML Frameworks').T\n",
    "df_count_hosting_notebook_2021.columns = df_count_hosting_notebook_2021.columns.str.strip()\n",
    "\n",
    "hosting_notebook_2020 = ['Q10_Part_1',\n",
    "                         'Q10_Part_2',\n",
    "                         'Q10_Part_3',\n",
    "                         'Q10_Part_4',\n",
    "                         'Q10_Part_5',\n",
    "                         'Q10_Part_6',\n",
    "                         'Q10_Part_7',\n",
    "                         'Q10_Part_8',\n",
    "                         'Q10_Part_9',\n",
    "                         'Q10_Part_10',\n",
    "                         'Q10_Part_11',\n",
    "                         'Q10_Part_12',\n",
    "                         'Q10_Part_13',\n",
    "                         'Q10_OTHER']\n",
    "\n",
    "df_hosting_notebook_2020 = pros_2020[hosting_notebook_2020]\n",
    "count_hosting_notebook_2020 = pd.Series(df_hosting_notebook_2020[hosting_notebook_2020].squeeze().values.ravel()).value_counts()\n",
    "\n",
    "df_count_hosting_notebook_2020 = pd.DataFrame(count_hosting_notebook_2020)\n",
    "df_count_hosting_notebook_2020 = df_count_hosting_notebook_2020.reset_index()\n",
    "df_count_hosting_notebook_2020.columns = ['ML Frameworks', 'Counts']\n",
    "\n",
    "df_count_hosting_notebook_2020 = df_count_hosting_notebook_2020.set_index('ML Frameworks').T\n",
    "df_count_hosting_notebook_2020.columns = df_count_hosting_notebook_2020.columns.str.strip()\n",
    "\n",
    "hosting_notebook_2019 =['Q17_Part_1',\n",
    "                        'Q17_Part_2',\n",
    "                        'Q17_Part_3',\n",
    "                        'Q17_Part_4',\n",
    "                        'Q17_Part_5',\n",
    "                        'Q17_Part_6',\n",
    "                        'Q17_Part_7',\n",
    "                        'Q17_Part_8',\n",
    "                        'Q17_Part_9',\n",
    "                        'Q17_Part_10',\n",
    "                        'Q17_Part_11',\n",
    "                        'Q17_Part_12',\n",
    "                        'Q17_OTHER_TEXT']\n",
    "\n",
    "df_hosting_notebook_2019 = pros_2019[hosting_notebook_2019]\n",
    "count_hosting_notebook_2019 = pd.Series(df_hosting_notebook_2019[hosting_notebook_2019].squeeze().values.ravel()).value_counts()\n",
    "\n",
    "df_count_hosting_notebook_2019 = pd.DataFrame(count_hosting_notebook_2019)\n",
    "df_count_hosting_notebook_2019 = df_count_hosting_notebook_2019.reset_index()\n",
    "df_count_hosting_notebook_2019.columns = ['ML Frameworks', 'Counts']\n",
    "\n",
    "df_count_hosting_notebook_2019 = df_count_hosting_notebook_2019.set_index('ML Frameworks').T\n",
    "df_count_hosting_notebook_2019.columns = df_count_hosting_notebook_2019.columns.str.strip()\n",
    "\n",
    "# --- Clean up for merge ---\n",
    "\n",
    "df_count_hosting_notebook_2019 = df_count_hosting_notebook_2019[['Kaggle Notebooks (Kernels)', 'Google Colab', 'Binder / JupyterHub', 'Microsoft Azure Notebooks',\n",
    "                               'AWS Notebook Products (EMR Notebooks, Sagemaker Notebooks, etc)',\n",
    "                               'IBM Watson Studio',\n",
    "                               'Paperspace / Gradient',\n",
    "                               'FloydHub',\n",
    "                              'Code Ocean']]\n",
    "\n",
    "df_count_hosting_notebook_2019['total'] = df_count_hosting_notebook_2019.sum(axis=1)\n",
    "df_count_hosting_notebook_2019[['Kaggle Notebooks (Kernels)', \n",
    "                                'Google Colab', \n",
    "                                'Binder / JupyterHub', \n",
    "                                'AWS Notebook Products (EMR Notebooks, Sagemaker Notebooks, etc)',\n",
    "                                'total']]\n",
    "\n",
    "df_count_hosting_notebook_2019 = df_count_hosting_notebook_2019.rename(columns = \n",
    "                                     {'Kaggle Notebooks (Kernels)': 'Kaggle Notebooks', \n",
    "                                'Google Colab': 'Colab Notebooks',\n",
    "                                      'Microsoft Azure Notebooks': 'Azure Notebooks',\n",
    "                                'Binder / JupyterHub': 'Binder / JupyterHub', \n",
    "                                'AWS Notebook Products (EMR Notebooks, Sagemaker Notebooks, etc)': 'Amazon Sagemaker Studio',\n",
    "                                'total': 'total'\n",
    "                                     })\n",
    "\n",
    "df_count_hosting_notebook_2020 = df_count_hosting_notebook_2020.drop('None', axis = 1)\n",
    "df_count_hosting_notebook_2020['total'] = df_count_hosting_notebook_2020.sum(axis = 1)\n",
    "df_count_hosting_notebook_2021 = df_count_hosting_notebook_2021.drop('None', axis = 1)\n",
    "df_count_hosting_notebook_2021['total'] = df_count_hosting_notebook_2021.sum(axis = 1)\n",
    "\n",
    "df_count_hosting_notebook_2021 = df_count_hosting_notebook_2021.rename(columns = {\"Amazon Sagemaker Studio Notebooks\": \"Amazon Sagemaker Studio\"})\n",
    "\n",
    "\n",
    "\n",
    "#  --- Now merge ---\n",
    "\n",
    "hosting_notebook_merge = pd.concat([df_count_hosting_notebook_2019, df_count_hosting_notebook_2020, df_count_hosting_notebook_2021])\n",
    "hosting_notebook_merge.index = ['2019', '2020', '2021']\n",
    "hosting_notebook_merge = hosting_notebook_merge.fillna(0)\n",
    "top_notebooks_used = hosting_notebook_merge[['Kaggle Notebooks', \n",
    "                        'Colab Notebooks', \n",
    "                        'Binder / JupyterHub', \n",
    "                        'Azure Notebooks', \n",
    "                        'IBM Watson Studio', \n",
    "                        'Amazon Sagemaker Studio', \n",
    "                        'total']]\n",
    "\n",
    "top_notebooks_used_perc = top_notebooks_used[['Kaggle Notebooks', \n",
    "                        'Colab Notebooks', \n",
    "                        'Binder / JupyterHub', \n",
    "                        'Azure Notebooks', \n",
    "                        'IBM Watson Studio', \n",
    "                        'Amazon Sagemaker Studio', \n",
    "                        'total']].div(top_notebooks_used['total'], axis = 0)\n",
    "\n",
    "# --- Plot ---\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "\n",
    "top_notebooks_used_perc[['Kaggle Notebooks', \n",
    "                        'Colab Notebooks', \n",
    "                        'Binder / JupyterHub', \n",
    "                        'Azure Notebooks', \n",
    "                        'IBM Watson Studio', \n",
    "                        'Amazon Sagemaker Studio']].plot(kind='bar', \n",
    "                                                         stacked = True,\n",
    "                                                        ax=ax,\n",
    "                                                     color = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf'])\n",
    "\n",
    "\n",
    "ax.set_title(\"Proportion of hosted notebook products usage\", fontsize ='large', pad=20)\n",
    "ax.set_xlabel('Year', fontsize='medium', labelpad=20)\n",
    "ax.set_ylabel('Percentage', fontsize='medium', labelpad=20)\n",
    "ax.legend(bbox_to_anchor = (1.7, 0.6), fontsize=20)\n",
    "\n",
    "plt.savefig(\"11.2 Softpower Notebook.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "share_deploy_2021 = [\n",
    "    'Q39_Part_1',\n",
    "    'Q39_Part_2',\n",
    "    'Q39_Part_3',\n",
    "    'Q39_Part_4',\n",
    "    'Q39_Part_5',\n",
    "    'Q39_Part_6',\n",
    "    'Q39_Part_7',\n",
    "    'Q39_Part_8',\n",
    "    'Q39_Part_9',\n",
    "    'Q39_OTHER'\n",
    "]\n",
    "\n",
    "df_share_deploy_2021 = pros_2021[share_deploy_2021]\n",
    "count_share_deploy_2021 = pd.Series(df_share_deploy_2021[share_deploy_2021].squeeze().values.ravel()).value_counts()\n",
    "\n",
    "df_count_share_deploy_2021 = pd.DataFrame(count_share_deploy_2021)\n",
    "df_count_share_deploy_2021 = df_count_share_deploy_2021.reset_index()\n",
    "df_count_share_deploy_2021.columns = ['Platforms', 'Counts']\n",
    "\n",
    "df_count_share_deploy_2021 = df_count_share_deploy_2021.set_index('Platforms').T\n",
    "df_count_share_deploy_2021.columns = df_count_share_deploy_2021.columns.str.strip()\n",
    "\n",
    "share_deploy_2020 =[\n",
    "    'Q36_Part_1',\n",
    "    'Q36_Part_2',\n",
    "    'Q36_Part_3',\n",
    "    'Q36_Part_4',\n",
    "    'Q36_Part_5',\n",
    "    'Q36_Part_6',\n",
    "    'Q36_Part_7',\n",
    "    'Q36_Part_8',\n",
    "    'Q36_Part_9',\n",
    "    'Q36_OTHER']\n",
    "\n",
    "df_share_deploy_2020 = pros_2020[share_deploy_2020]\n",
    "count_share_deploy_2020 = pd.Series(df_share_deploy_2020[share_deploy_2020].squeeze().values.ravel()).value_counts()\n",
    "\n",
    "df_count_share_deploy_2020 = pd.DataFrame(count_share_deploy_2020)\n",
    "df_count_share_deploy_2020 = df_count_share_deploy_2020.reset_index()\n",
    "df_count_share_deploy_2020.columns = ['Platforms', 'Counts']\n",
    "\n",
    "df_count_share_deploy_2020 = df_count_share_deploy_2020.set_index('Platforms').T\n",
    "df_count_share_deploy_2020.columns = df_count_share_deploy_2020.columns.str.strip()\n",
    "\n",
    "# --- Merge ---\n",
    "merged_share_deploy = pd.concat([df_count_share_deploy_2020, df_count_share_deploy_2021])\n",
    "merged_share_deploy.index = ['2020', '2021']\n",
    "\n",
    "merged_share_deploy = merged_share_deploy.drop('I do not share my work publicly', axis = 1)\n",
    "merged_share_deploy['total'] = merged_share_deploy.sum(axis = 1)\n",
    "merged_share_deploy = merged_share_deploy.div(merged_share_deploy['total'], axis = 0)\n",
    "merged_share_deploy = merged_share_deploy.drop('total', axis = 1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "\n",
    "merged_share_deploy[['GitHub', 'Kaggle', 'Personal blog', 'Shiny']].plot(kind='bar', \n",
    "                                                         stacked = True,\n",
    "                                                        ax=ax,\n",
    "                                                     color = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf'])\n",
    "\n",
    "\n",
    "ax.set_title(\"Platform to share or deploy ML applications\", fontsize ='large', pad=20)\n",
    "ax.set_xlabel('Year', fontsize='medium', labelpad=20)\n",
    "ax.set_ylabel('Percentage', fontsize='medium', labelpad=20)\n",
    "ax.legend(bbox_to_anchor = (1.45, 0.6), fontsize=20)\n",
    "\n",
    "plt.savefig(\"11.3 Softpower ML repository.png\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from subprocess import check_output\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "#mpl.rcParams['figure.figsize']=(8.0,6.0)    #(6.0,4.0)\n",
    "mpl.rcParams['font.size']=12                #10 \n",
    "mpl.rcParams['savefig.dpi']=100             #72 \n",
    "mpl.rcParams['figure.subplot.bottom']=.1 \n",
    "\n",
    "\n",
    "stopwords = set(STOPWORDS)\n",
    "f = open(\"../input/big-tech-keynotes/2020_keynote_amzn.txt\", \"r\", encoding='utf-8')\n",
    "file_content = f.read()\n",
    "\n",
    "wordcloud = WordCloud(\n",
    "                          background_color='white',\n",
    "                          stopwords=stopwords,\n",
    "                          max_words=200,\n",
    "                          max_font_size=40, \n",
    "                          random_state=42\n",
    "                         ).generate(file_content)\n",
    "\n",
    "print(wordcloud)\n",
    "fig = plt.figure(1)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "fig.savefig(\"amzn_keynote_clouds.png\", dpi=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS)\n",
    "f = open(\"../input/big-tech-keynotes/2021_google_io.txt\", \"r\", encoding='utf-8')\n",
    "file_content = f.read()\n",
    "\n",
    "wordcloud = WordCloud(\n",
    "                          background_color='white',\n",
    "                          stopwords=stopwords,\n",
    "                          max_words=200,\n",
    "                          max_font_size=40, \n",
    "                          random_state=42\n",
    "                         ).generate(file_content)\n",
    "\n",
    "print(wordcloud)\n",
    "fig = plt.figure(1)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "fig.savefig(\"google_io_2021.png\", dpi=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS)\n",
    "f = open(\"../input/big-tech-keynotes/2021_ignite_2021.txt\", \"r\", encoding='utf-8')\n",
    "file_content = f.read()\n",
    "\n",
    "wordcloud = WordCloud(\n",
    "                          background_color='white',\n",
    "                          stopwords=stopwords,\n",
    "                          max_words=200,\n",
    "                          max_font_size=40, \n",
    "                          random_state=42\n",
    "                         ).generate(file_content)\n",
    "\n",
    "print(wordcloud)\n",
    "fig = plt.figure(1)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "fig.savefig(\"msft_ignite_2021.png\", dpi=900)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
