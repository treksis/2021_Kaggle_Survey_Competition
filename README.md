<h1>2021 Kaggle competition</h1>
    <p><strong>Note:</strong> For all charts in this module, I only selected working Professionals.</p>
<p>Non-professionals were defined as those who answered Job Title as either:</p>
<ul>
  <li>Student</li>
  <li>Currently not employed</li>
  <li>Who didn't answer the question (NaN)</li>
</ul>

<div style="font-size:18px; line-height:1.7; color:black;">
    <h1>Data Science, The Next Battle Ground</h1>
</div>
    <div style="font-size:18px; line-height:1.7; color:black;">
    <h2>Table of contents</h2>
    <ol type="I">
        <li>Data Science is key for the future of cloud industries</li>
            <ul>
                <li>Highlights from the Big Tech</li>
                <li>Future application of DS</li>
            </ul>
        <li>Google, a mile ahead</li>
            <ul>
                <li>Softpower advantage: Colab, Kaggle, Tensorflow</li>
                <li>Hardware advantage: TPU</li>
            </ul>
        <li>Current status of data science</li>
        <ul>
            <li>Less researchers, More engineers</li>
            <li>Computer vision and NLP took off a baby step</li>
        </ul>
</ol>
</div>

<div style="font-size:18px; line-height:1.7; color:black;">
    <h2>Summary</h2>
    <ul>
        <li>At the end of the day, Cloud industries converge to data science.</li>
        <li>Google already integrated its vertical IaaS and PaaS pipeline.</li>
        <li>Path to the mainstream is now a matter of time. The industry is asking for a more practical labour force.</li>
    </ul>
    </div>
    
<div style="font-size:18px; line-height:1.7; color:black;">
<h1><strong>Introduction</strong></h1>
   
<p>It has been more than a year and a half since the first lockdown announcement in North America. Pandemic has had a big impact not only on our lives but also on the cloud industry. On April 30th 2020, Microsoft CEO Satya Nadella said "We saw 2 years of digital transformation in 2 months". As we are seeing the light at the end of the covid tunnel, the rate of digitalization will likely deaccelerate. The beautiful part is that the cloud penetration will continue in post covid world. According to new CEO of Amazon Andy Jassy, a mere 4% of IT spending currently goes into the cloud. That being said there's still tremendous upside potential left.</p>
    <p>Till now on, the Cloud industries' focus was mostly on how to efficiently store and provide hosting services. The result was an oligopoly of a few giant players. Amazon, the number one IaaS/PaaS solution provider, Azure as the Second and Google, the third. The chance that these players to lose their shares from this framework is low because it is hard to differentiate themselves from each other at this stage.</p>
        <p>So, the vendors were seeking new opportunities outside of the existing scope. The result was the addition of analytical features and introduction of second generation of cloud computing service such as Serverless computing or Function as a Service. However, these changes are not big enough to shake the existing landscape.</p>
    <p>Along with the adoption of multi-clouds, the importance of data management is rising exponentially. As such, it is natural that the vendors' interest to shift from gathering data to processing data.</p>
</div>

<img src="https://github.com/treksis/2021_Kaggle_Survey_Competition/blob/main/Evolution%20of%20cloud%20industry.png?raw=true" alt="Evolution of Cloud">

<div style="font-size:25px; line-height:1.7; color:black;">
<hr>
    <h2><Strong>1. Highlights from the big three's key events</Strong></h2>
<hr>
</div>

<div style="font-size:18px; line-height:1.7; color:black;">
<ul>
    <li>Each year the big three host a keynote event where it addresses the future strategic plan</li>
    <li>Although each vendor has a different priority and different target audiences, there is no doubt that <u>machine learning is common practice</u></li>
    </ul>
</div>

<img src="https://github.com/treksis/2021_Kaggle_Survey_Competition/blob/main/cloud%20keynotes.jpg?raw=true" alt="Highligts from the big tech">

<div style="font-size:8px; line-height:1.7; color:black;">

Source: Amazon Web Services. "AWS re:Invent 2020 - Keynote with Andy Jassy." Youtube, uploaded by Amazon Web Services, 11 Dec. 2020, https://www.youtube.com/watch?v=xZ3k7Fd6_eU&t=675s.<Br>
    
Source: Google. "Google Keynote (Google I/O ‘21) - American Sign Language." Youtube, uploaded by Google. 18 May. 2021, https://www.youtube.com/watch?v=Mlk888FiI8A&t=2s.<Br>
    
Source: Microsoft "Microsoft Ignite 2021." Youtube, uploaded by Microsoft Ignite. 02 Nov. 2021, https://www.youtube.com/watch?v=PraEcNDGSqY&t=2s.
</div>
  
<div style="font-size:25px; line-height:1.7; color:black;">
<hr>
    <h2><Strong>2. Application of data science in the future</Strong></h2>
<hr>
</div>
<div style="font-size:18px; line-height:1.7; color:black;">
    <ul>
        <li>Machines can outperform humans in repetitive tasks. Drivers, factory manufacturing, dispatchers, and cashiers are no longer an exception.</li>
        <li>Most companies are already using robots in their factories.</li>
        <li>Tesla is already trying to replace the human driver, Amazon's cashierless GO is under practice, and chatbots are replacing the call centers.</li>
        <li><Strong>The fourth industrial revolution has already started.</Strong> The data is <u>the single most important commodity</u> in the next revolution.</li>
    </ul>
</div>

<img src="https://github.com/treksis/2021_Kaggle_Survey_Competition/blob/main/cloud%20application.jpg?raw=true" alt="Evolution of Cloud">

<div style="font-size:8px; line-height:1.7; color:black;">
Source: Kumar, Bharani. "AI Applications Assisting Specialists to Increase Their Efficiency." 23 Apr. 2020, https://360digitmg.com/application-of-artificial-intelligence.
    <Br>    
Source: Maguire, James. "12 Examples of Artificial Intelligence: AI Powers Business." 13 Sep. 2019, https://www.datamation.com/artificial-intelligence/12-examples-of-artificial-intelligence-ai-powers-business/.
    
</div>
  
  
<div style="font-size:25px; line-height:1.7; color:black;">
<hr>
    <h2><Strong>4. Tensorflow, the preferred ML Framework</Strong></h2>
<hr>
</div>

<div style="font-size:18px; line-height:1.7; color:black;">
<ul>
    <li>Created by the Google Brain team, TensorFlow is an open source library for numerical computation and large-scale machine learning.</li>
    <li>Keras runs on top of the Tensorflow.</li>
    <li><Strong>While TensorFlow remains dominant ML framework</Strong>, another ML framework (Pytorch) led by Facebook AI is catching up quickly.</li>
    <li>Potential risk is that Google's TensorFlow end up being similar to Google's front-end framework Angular.</li>
</ul>
</div>

<img src="https://github.com/treksis/2021_Kaggle_Survey_Competition/blob/main/keras_tensor_pytorch2.png?raw=true" alt="Tensor_Pytorch">
  
<div style="font-size:25px; line-height:1.7; color:black;">
<hr>
    <h2><Strong>6. AutoML, Google already dominant, but big opportunity for the rest</Strong></h2>
<hr>
</div>

<div style="font-size:18px; line-height:1.7; color:black;">
<ul>
<li>Google leads since 2019</li>
<li>Besides Google, Amazon and Microsoft do not show particular strength.</li>
<li>Opportunities are here for relatively small players like <u>Databricks, H2O, and DataRobot.</u></li>
</ul>

</div>

<img src="https://github.com/treksis/2021_Kaggle_Survey_Competition/blob/main/autoML.png?raw=true" alt="AutoML">

<div style="font-size:25px; line-height:1.7; color:black;">
<hr>
    <h2><Strong>8. Then How much ?</Strong></h2>
<hr>
</div>
<div style="font-size:18px; line-height:1.7; color:black;">
    <ul>
        <li>NVIDIA generated <Strong>6.7 bln of revenues from the data center</Strong> segment in 2020.</li>
        <li>Which means, the big three spent <Strong>at least 1.6 bln dollars on GPU infrastruture</Strong> in 2020.</li>
        <li>This trend will likely accelerate further along with the data science penetration.</li>
    </ul>
</div>

<img src="https://github.com/treksis/2021_Kaggle_Survey_Competition/blob/main/nvidia_bigtech.png?raw=true" alt="NVIDIA's Earning">

<div style="font-size:25px; line-height:1.7; color:black;">
<hr>
    <h2><Strong>9. Why TPU over GPU?</Strong></h2>
<hr>
</div>

<div style="font-size:18px; line-height:1.7; color:black;">
<ul>
    <li>It seems natural for data professionals to use TPU because it is cheaper and faster than GPU</li>
    <li>The numbers of ALUs in TPUs are substantially higher than in GPUs making them a lot faster. <u>GPUs have between 2500 to 5000 ALUs per core, while TPUs have 32768 ALUs per core</u></li>
    <li>This chart compares the performance per WATT by processor released by Google. <Strong>At full operation, the economic feasibility of TPU is overwhelming.</Strong></li>
    </ul>
    
<img src="https://github.com/treksis/2021_Kaggle_Survey_Competition/blob/main/tpu_images.png?raw=true" alt="TPU performance">
  
</div>

<div style="font-size:8px; line-height:1.7; color:black;">
Source: Jouppi, N. P. et al. In-datacenter performance analysis of a tensor processing unit. Proc. 44th Int. Symp. Comp. Architecture (ISCA) https://doi.org/10.1145/3079856.3080246 (2017).<Br>
    
Source: Sato, Kaz. "What makes TPUs fine-tuned for deep learning?". Google Cloud, 31 Aug. 2018, https://cloud.google.com/blog/products/ai-machine-learning/what-makes-tpus-fine-tuned-for-deep-learning.
</div>

<div style="font-size:25px; line-height:1.7; color:black;">
<hr>
    <h2><Strong>10. The bottleneck</Strong></h2>
<hr>
</div>

<div style="font-size:18px; line-height:1.7; color:black;">
<ul>
        <li>The only concern for TPU is that if there is not enough data to fully operate the TPU, the relative performance drops sharply.  </li>
        <li>For example, most factories have to operate at full capacity to maximize profitability. The same logic applies to TPUs. <Strong>The smaller the batch size of the training, the weaker the relative performance of TPU.</Strong> As the AI market is still in its early growth phase, <Strong>there are not enough users to use all the computational capacity of the TPUs.</Strong></li>
        <li>For this reason, whenever the benchmark is released every year, Nvidia's strategy of taking a realistic approach to AI development and Google's strategy of pursuing the eventual ideals collide.</li>
    </ul>
</div>

<img src="https://github.com/treksis/2021_Kaggle_Survey_Competition/blob/main/tpu_performance.png?raw=true" alt="TPU+GPU usage">
  
<div style="font-size:8px; line-height:1.7; color:black;">
    
Source: Plathottam, S. J. DataDrivenInvestor. Medium, 29 Nov. 2018, https://medium.datadriveninvestor.com/comparing-gpu-and-tpu-training-performance-on-google-colaboratory-c1e54e26993f. Acessed 27 Nov 2021.<Br>
    
Source: Salvator, Dave. "Extending NVIDIA Performance Leadership with MLPerf Inference 1.0 Results." Deloper Blog, Nvidia, 22 Apr. 2021, https://developer.nvidia.com/blog/extending-nvidia-performance-leadership-with-mlperf-inference-1-0-results/.<Br>
    
Source: Tao Wang, Aarush Selvan. "Google demonstrates leading performance in latest MLPerf Benchmarks." Blog, Google, 1 Jul. 2021, https://cloud.google.com/blog/products/ai-machine-learning/google-wins-mlperf-benchmarks-with-tpu-v4.
</div>

<div style="font-size:25px; line-height:1.7; color:black;">
<hr>
    <h2><Strong>12. TPU Penetratrion Rate is Surprisingly Fast</Strong></h2>
<hr>
</div>

<div style="font-size:18px; line-height:1.7; color:black;">
<ul>
        <li>Google prepared early on its version of ML chips to reduce potential <Strong>GPU infrastructure cost burden.</Strong></li>
        <li>As you have seen in the previous charts, the appetite for Google's feature is amazingly high among data science professionals. These efforts worked out. <Strong>Google has successfully managed to penetrate TPU usage.</Strong></li>
    <li>There was a major TPU usage <u>jump in 2021</u></li>
        <li>Amazon did introduce its chip in 2021. However, Amazon does not possess as much soft power as Google. Thus, penetration will likely take some time.</li>
    </ul>
</div>

<img src="https://github.com/treksis/2021_Kaggle_Survey_Competition/blob/main/special%20hardware%20usage.png?raw=true" alt="TPU+GPU usage">

<div style="font-size:25px; line-height:1.7; color:black;">
<hr>
<h2><Strong>13. Not just fast, but Broadly</Strong></h2>
<hr>
</div>
    
<div style="font-size:18px; line-height:1.7; color:black;">
<ul>
<li>Google's TPUs ared used widely <Strong>regardless of the size of the company</Strong></li>
<li>A reason behind this would be <u>TPU started to support the Pytorch framework as of 2020.</u></li>
</ul>
</div>  

<img src="https://github.com/treksis/2021_Kaggle_Survey_Competition/blob/main/moneyspenton.jpg?raw=true" alt="TPU+GPU usage">
  
<div style="font-size:25px; line-height:1.7; color:black;">
<hr>
    
<h2><Strong>14. TPU VS GPU, Battle is reminiscent of Bitcoin mining</Strong></h2>

<hr>
</div>

<div style="font-size:18px; line-height:1.7; color:black;">
<ul>
        <li>There was a time when Bitcoin was mined through GPUs. The increasing difficulty in mining made GPUs unprofitable compared to ASICs which provided a much higher hash rate per dollar.</li>
        <li>Similarly, TPU will become more attractive with an ever-increasing amount of data processing in the future.</li>  
    </ul>
</div>

<img src="https://github.com/treksis/2021_Kaggle_Survey_Competition/blob/main/bitcoin%20mining.png?raw=true" alt="TPU+GPU usage">

<div style="font-size:8px; line-height:1.7; color:black;">
Source: "Bitcoin Mining Profitability historical chart." Bitinfocharts. 28 Nov. 2021, https://bitinfocharts.com/comparison/bitcoin-mining_profitability.html#alltime.
</div>
  
<div style="font-size:25px; line-height:1.7; color:black;">
<hr>
    <h2><Strong>15. TPU, Time is on your side</Strong></h2>

<hr>
</div>

<div style="font-size:18px; line-height:1.7; color:black;">
<ul>
        <li>Data usage is expected to increase exponentially both from the consumer side and the business side.</li>
        <li>The key difference in the upcoming era of digitalization is that there will be <Strong>more data created by machines than the data created by humans.</Strong></li>
        <li>With the increased adoption of 5G, IoT, AR/VR, as well as metaverse, data processing is expected to explode.</li>
    </ul>
</div>
     
<img src="https://github.com/treksis/2021_Kaggle_Survey_Competition/blob/main/human_machine_data.png?raw=true" alt="TPU+GPU usage">
    
<div style="font-size:8px; line-height:1.7; color:black;">
Source: "The Exponential Growth of Data." Insidebigdata. 16 Feb. 2017, https://insidebigdata.com/2017/02/16/the-exponential-growth-of-data/.
</div>
  
<div style="font-size:25px; line-height:1.7; color:black;">
<hr>
    <h2><Strong>16. Digital transformation / Data science everywhere</Strong><h2>
<hr>
</div>

<div style="font-size:18px; line-height:1.7; color:black;">
<ul>
        <li>The key difference in data science professionals distribution in 2018 and 2021 is <Strong>Computers/Technology industry proportion experienced <u>a large decline.</u></Strong></li>
        <li>Academics/Education gained significant shares followed by Manufacturing/Fabrication and Medical/Pharmaceutical industries. A sign that data science is spreading all over the industry.</li>
        <li>Data science professionals are distributed regardless of the size of the company which further confirm data science is on the path of mainstream business.</li>
    </ul>
</div>

<img src="https://github.com/treksis/2021_Kaggle_Survey_Competition/blob/main/data_pros_distr.png?raw=true" alt="DS distribution vs. industry">
      
<div style="font-size:25px; line-height:1.7; color:black;">
    <hr>
<h2><strong>17. Industry is asking less scientists, but more engineers </strong></h2>
    <hr>
</div>

<div style="font-size:18px; line-height:1.7; color:black;">
<ul>
  <li>The number of software engineers and data scientists in the Computer/Technology field declined in 2021.</li>
  <li>While Research scientists working in the Academic/Education field declined, the number of data scientists and software engineers increased in 2021.</li>
  <li><strong>The machine learning engineer role is newly added in 2021.</strong></li>
  <li>MLE's tasks in the workplace are the hybrid of traditional data scientists and software engineers. <strong>Focusing on less analytics, but more on managing product lines.</strong></li>
  <li>Much like other industries, the proportion of academia and scientists will gradually go down and be replaced by engineers.</li>
    <li><Strong>Job market shows a sign of great rotation from research to real world practice.</Strong></li>
</ul>
</div>

<img src="https://github.com/treksis/2021_Kaggle_Survey_Competition/blob/main/more%20engi.png?raw=true" alt="enginners in demand">
      
<div style="font-size:25px; line-height:1.7; color:black;">
<hr>
<h2><strong>18. Current Status of Computer Vision and Natural language processing</strong></h2>
<hr>
</div>

<div style="font-size:18px; line-height:1.7; color:black;">
<ul>
  <li>The public acknowledges these two technologies to be the true adoption of data science in conjunction with robotics.</li>
  <li>25% of respondents in the Computer/Technology industry said they are exposed to NLP technology. The rests sit only around 15%.</li>
  <li>NLP is already adopted in the form of chatbot or speech recognition or translation. <strong>Any tasks that require inter-person communication or paperwork will eventually apply NLP technology.</strong></li>
    <Br>
  <li>Only 35% of respondents in the Computer/Technology industry said they are exposed to computer vision technology. 29% of respondents were from the Academics/Education industry. The rest are hovering around 20%.</li>
  <li>Tesla officially launched its full self-driving subscription package on July 22, 2021, Hyundai completed its Boston dynamics acquisition on June 21, 2021, Deepmind acquired physics simulator MuJoCo and has made it open-source. Facebook changed its company name to Meta. <strong>Given that computer vision is a must-have from robotics to the metaverse, the number of respondents who will say "YES" is likely to explode in near the future.</strong></li>
</ul>

</div>

<img src="https://github.com/treksis/2021_Kaggle_Survey_Competition/blob/main/nlp_vision.png?raw=true" alt="NLP and CV">
  
<div style="font-size:18px; line-height:1.7; color:black;">
    <h2>Conclusion. Behind the scenes</h2>
    <ul>
        <li>Now, I have a better understand why cloud industries are obsessed with data science. IaaS and PaaS potential is amazingly high.</li>
        <li>I am  surprised how well Google is prepared for the next battleground.</li>
        <li>I am shocked about the performance of Google's NPU and how well it is penetrated inside the data science community.</li>
        <li>I am surpised the adoption of computer vision and natural language processing was that small within data science community.</li>
        <li>Thanks to the Kaggle community and moderator to share the valuable data set.</li>
    </ul>
    </div>
  
<div style="font-size:18px; line-height:1.7; color:black;">
    <h2>Reference</h2>
    </div>

[1] Amazon Web Services. "AWS re:Invent 2020 - Keynote with Andy Jassy." Youtube, uploaded by Amazon Web Services, 11 Dec. 2020, https://www.youtube.com/watch?v=xZ3k7Fd6_eU&t=675s.

[2] Google. "Google Keynote (Google I/O ‘21) - American Sign Language." Youtube, uploaded by Google. 18 May. 2021, https://www.youtube.com/watch?v=Mlk888FiI8A&t=2s.

[3] Microsoft "Microsoft Ignite 2021." Youtube, uploaded by Microsoft Ignite. 02 Nov. 2021, https://www.youtube.com/watch?v=PraEcNDGSqY&t=2s.

[4] Kumar, Bharani. "AI Applications Assisting Specialists to Increase Their Efficiency." 23 Apr. 2020, https://360digitmg.com/application-of-artificial-intelligence.

[5] Maguire, James. "12 Examples of Artificial Intelligence: AI Powers Business." 13 Sep. 2019, https://www.datamation.com/artificial-intelligence/12-examples-of-artificial-intelligence-ai-powers-business/.

[6] Jouppi, N. P. et al. In-datacenter performance analysis of a tensor processing unit. Proc. 44th Int. Symp. Comp. Architecture (ISCA) https://doi.org/10.1145/3079856.3080246 (2017).

[7] Sato, Kaz. "What makes TPUs fine-tuned for deep learning?". Google Cloud, 31 Aug. 2018, https://cloud.google.com/blog/products/ai-machine-learning/what-makes-tpus-fine-tuned-for-deep-learning.

[8] Plathottam, S. J. DataDrivenInvestor. Medium, 29 Nov. 2018, https://medium.datadriveninvestor.com/comparing-gpu-and-tpu-training-performance-on-google-colaboratory-c1e54e26993f. Acessed 27 Nov 2021.

[9] Salvator, Dave. "Extending NVIDIA Performance Leadership with MLPerf Inference 1.0 Results." Deloper Blog, Nvidia, 22 Apr. 2021, https://developer.nvidia.com/blog/extending-nvidia-performance-leadership-with-mlperf-inference-1-0-results/.

[10] Tao Wang, Aarush Selvan. "Google demonstrates leading performance in latest MLPerf Benchmarks." Blog, Google, 1 Jul. 2021, https://cloud.google.com/blog/products/ai-machine-learning/google-wins-mlperf-benchmarks-with-tpu-v4.

[11] Wikichip. ""Neural Processor." Wikichip, 4 Nov. 2021, https://en.wikichip.org/wiki/neural_processor. Acessed 27 Nov 2021.

[12] "Bitcoin Mining Profitability historical chart." Bitinfocharts. 28 Nov. 2021, https://bitinfocharts.com/comparison/bitcoin-mining_profitability.html#alltime.

[13] "The Exponential Growth of Data." Insidebigdata. 16 Feb. 2017, https://insidebigdata.com/2017/02/16/the-exponential-growth-of-data/.





  
